{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1898623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamlit: Web app framework (No html/css required)\n",
    "# openai: OpenAI API wrapper\n",
    "# faiss-cpu: Vector Database\n",
    "# langchain: LLM wrapper\n",
    "# opencv-python: Image processing\n",
    "# pandas: Data manipulation\n",
    "# sqlalchemy: Database connection\n",
    "\n",
    "import openai\n",
    "import faiss\n",
    "import langchain\n",
    "import pandas as pd\n",
    "from sqlalchemy import (\n",
    "    select, create_engine, Table, Column, Integer, String, MetaData,\n",
    "    ForeignKey, ForeignKeyConstraint, UniqueConstraint, LargeBinary, text\n",
    ")\n",
    "from sqlalchemy.orm import Session, sessionmaker\n",
    "\n",
    "# PyMuPDF, pdfplumber, or OCR\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "import re\n",
    "import pdfplumber\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# For Image Display within the df\n",
    "from IPython.display import display, Image\n",
    "from PIL import Image, ImageOps\n",
    "from io import BytesIO\n",
    "from IPython.display import display, Image as IPImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e07cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#josiacdwojaoicjdoiaociwdjcoaijcadoijaoij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e07f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values with your actual database info\n",
    "username = \"postgres\"\n",
    "password = \"MPAMS\"\n",
    "host = \"localhost\"\n",
    "port = \"5432\"\n",
    "database = \"MPDB\"\n",
    "\n",
    "\n",
    "# SQLAlchemy connection URL\n",
    "DATABASE_URL = f\"postgresql://{username}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "# Create engine\n",
    "engine = create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0628c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the 2 tables\n",
    "metadata = MetaData()\n",
    "\n",
    "master_parts_list = Table(\n",
    "    \"master_parts_list\", metadata,\n",
    "    Column(\"mpl_id\", Integer, primary_key=True),\n",
    "    Column(\"pdf_id\", String, nullable=False),\n",
    "    Column(\"year\", Integer, nullable=False),\n",
    "    Column(\"brand\", String, nullable=False),\n",
    "    Column(\"model\", String, nullable=False),\n",
    "    Column(\"section\", Integer, nullable=False), # AKA \"fig_no\" for pdf\n",
    "    Column(\"component_name\", String, nullable=False),\n",
    "    Column(\"ref_no\", Integer, nullable=False),\n",
    "    Column(\"part_no\", String, nullable=False),\n",
    "    Column(\"description\", String, nullable=False),\n",
    "    Column(\"remarks\", String),\n",
    "    Column(\"image_id\", String, ForeignKey(\"parts_images.image_id\", ondelete=\"SET NULL\"))\n",
    ")\n",
    "\n",
    "parts_images = Table(\n",
    "    \"parts_images\", metadata,\n",
    "    Column(\"image_id\", String, primary_key=True),\n",
    "    Column(\"pdf_id\", String, nullable=False),\n",
    "    Column(\"fig_no\", Integer, nullable=False),\n",
    "    Column(\"image\", LargeBinary, nullable=False),\n",
    ")\n",
    "\n",
    "# Create the tables\n",
    "metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ab4148",
   "metadata": {},
   "source": [
    "### Week 3: Inventory Data Extraction & Indexing (2aâ€“2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0935ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse PDFs (Use PyMuPDF, pdfplumber, or OCR)\n",
    "# Store structured data in a relevant data warehouse or database (e.g., SQLite/PostgreSQL).\n",
    "# Use vector embeddings and FAISS to enable semantic search and RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a9f13bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format 1: Yamaha\n",
    "# Important images from page 6-60\n",
    "pdf_1 = \"Manuals/AEROX 155 '19 (B65P, B65R, B65S).pdf\"\n",
    "pdf_2= \"Manuals/FJR1300A '15 (1MCH, 1MCG).PDF\"\n",
    "\n",
    "# Format 2: Honda\n",
    "pdf_3 = \"Manuals/CRF1000 A_PC_13MJPG02_(G.H).pdf\"\n",
    "pdf_4 = \"Manuals/NC750XAP_13MKWM02_PC_2022_2023.pdf\"\n",
    "\n",
    "pdf_path = pdf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0ebd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview extracted raw text\n",
    "import pdfplumber\n",
    "\n",
    "start_page = 23\n",
    "end_page = 23\n",
    "\n",
    "# Initialize a variable to hold all extracted text\n",
    "all_text = \"\"\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    # Loop through the specified page range\n",
    "    for page_num in range(start_page - 1, end_page):  # page_num is 0-indexed, so subtract 1 from start_page\n",
    "        page = pdf.pages[page_num]\n",
    "        text = page.extract_text()  # Extract text from the page\n",
    "        \n",
    "        if text:  # If the page contains text\n",
    "            all_text += f\"\\n--- Page {page_num + 1} ---\\n{text}\\n\"  # page_num + 1 to keep it 1-indexed in output\n",
    "\n",
    "# Optionally, print the extracted text or save to a file\n",
    "print(all_text)\n",
    "\n",
    "# If you want to save the text to a text file:\n",
    "with open(\"extracted_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3199ccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inserted 38 new images for 'AEROX155'.\n",
      "[INFO] Inserted parts data for 'AEROX155'.\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "# ---------- HELPERS ----------\n",
    "def extract_pdf_id(pdf_path):\n",
    "    base_filename = os.path.basename(pdf_path).split('.')[0]\n",
    "    match = re.match(r\"([A-Za-z0-9 ]+)\", base_filename)\n",
    "    if match:\n",
    "        return match.group(1).replace(\" \", \"\")  # Remove all spaces\n",
    "    return None\n",
    "\n",
    "def extract_year(pdf_path):\n",
    "    year_match = re.search(r\"'(\\d{2})\", pdf_path)\n",
    "    return f\"20{year_match.group(1)}\" if year_match else None\n",
    "\n",
    "def extract_model(pdf_path):\n",
    "    base_filename = os.path.basename(pdf_path)\n",
    "    match = re.search(r\"\\((.*?)\\)\", base_filename)\n",
    "    if match:\n",
    "        return match.group(1)  # e.g., \"B65P, B65R, B65S\"\n",
    "    return None\n",
    "\n",
    "# ---------- IMAGE EXTRACTION ----------\n",
    "def normalize_image_background(image_bytes):\n",
    "    img = Image.open(BytesIO(image_bytes)).convert(\"L\")  # Grayscale\n",
    "    mean_brightness = sum(img.getdata()) / (img.width * img.height)\n",
    "\n",
    "    if mean_brightness < 128:  # Invert if it's a dark background\n",
    "        img = ImageOps.invert(img)\n",
    "\n",
    "    img = img.convert(\"RGB\")  # Convert back to RGB\n",
    "\n",
    "    output = BytesIO()\n",
    "    img.save(output, format=\"PNG\")\n",
    "    return output.getvalue()\n",
    "\n",
    "def extract_images_with_fig_labels(pdf_path, pdf_id, engine):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    data = []\n",
    "\n",
    "    # Step 1: Get existing (pdf_id, fig_no) combos from DB\n",
    "    existing_figs = get_existing_fig_combos(engine, pdf_id)\n",
    "\n",
    "    seen_figs = set()  # Track unique figs within the PDF\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "\n",
    "        matches = re.findall(r\"FIG\\.\\s*([\\w-]+)\", text)\n",
    "        if not matches:\n",
    "            continue\n",
    "\n",
    "        fig_no = matches[0]\n",
    "\n",
    "        if fig_no in seen_figs or fig_no in existing_figs:\n",
    "            continue  # Skip if already handled or exists in DB\n",
    "\n",
    "        image_list = page.get_images(full=True)\n",
    "        if not image_list:\n",
    "            continue\n",
    "\n",
    "        xref = image_list[0][0]\n",
    "        base_image = doc.extract_image(xref)\n",
    "        image = normalize_image_background(base_image[\"image\"])\n",
    "\n",
    "        image_id = \"_\".join([pdf_id, fig_no])\n",
    "\n",
    "        data.append({\n",
    "            \"image_id\" : image_id,\n",
    "            \"pdf_id\": pdf_id,\n",
    "            \"fig_no\": fig_no,\n",
    "            \"image\": image\n",
    "        })\n",
    "        seen_figs.add(fig_no)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def get_existing_fig_combos(engine, pdf_id):\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(\n",
    "            text(\"SELECT fig_no FROM parts_images WHERE pdf_id = :pdf_id\"),\n",
    "            {\"pdf_id\": pdf_id}\n",
    "        )\n",
    "        return set(str(row[0]) for row in result.fetchall())  # Cast to str for consistent comparison\n",
    "\n",
    "# ---------- TEXT EXTRACTION ----------\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    all_text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text() or \"\"\n",
    "            lines = text.split('\\n')\n",
    "            first_line = lines[0].strip() if lines else \"\"\n",
    "            if not any(\"FIG.\" in line for line in lines):\n",
    "                continue\n",
    "            if \"NUMERICAL INDEX\" in first_line:\n",
    "                break\n",
    "            all_text += f\"\\n--- Page {page_num + 1} ---\\n{text}\\n\"\n",
    "    return all_text\n",
    "\n",
    "def yamaha_process_data(text, pdf_id, year, model, num_model):\n",
    "    rows = []\n",
    "    lines = text.strip().split('\\n')\n",
    "    section = c_name = prev_fig_no = prev_c_name = prev_ref_no = \"\"\n",
    "    collect_data = False\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line: continue\n",
    "        if line.startswith('FIG.'):\n",
    "            tokens = line.split()\n",
    "            if len(tokens) >= 3:\n",
    "                section = tokens[1]\n",
    "                c_name = \" \".join(tokens[2:])\n",
    "                prev_fig_no, prev_c_name = section, c_name\n",
    "                collect_data = True\n",
    "            continue\n",
    "        if not collect_data: continue\n",
    "        if not section:\n",
    "            section, c_name = prev_fig_no, prev_c_name\n",
    "\n",
    "        parts = line.split()\n",
    "        is_valid_data_line = (\n",
    "            len(parts) >= 2 and \n",
    "            (re.match(r'\\w+[-â€“]\\w+', parts[0]) or parts[0].isdigit())\n",
    "        )\n",
    "        if not is_valid_data_line:\n",
    "            continue\n",
    "\n",
    "        if parts[0].isdigit():\n",
    "            ref_no = parts[0]\n",
    "            part_no = parts[1]\n",
    "            rest = parts[2:]\n",
    "            prev_ref_no = ref_no\n",
    "        else:\n",
    "            ref_no = prev_ref_no\n",
    "            part_no = parts[0]\n",
    "            rest = parts[1:]\n",
    "\n",
    "        rest = \" \".join(rest).split()\n",
    "        description = remarks = \"\"\n",
    "        numbers = []\n",
    "        found_numbers = False\n",
    "        for item in rest:\n",
    "            if item.isdigit():\n",
    "                numbers.append(item)\n",
    "                found_numbers = True\n",
    "                continue\n",
    "            if not found_numbers:\n",
    "                description += item + \" \"\n",
    "            else:\n",
    "                remarks += item + \" \"\n",
    "        if len(numbers) > num_model:\n",
    "            description += numbers[0]\n",
    "\n",
    "        image_id = \"_\".join([pdf_id, section])\n",
    "\n",
    "        rows.append([pdf_id, year, \"Yamaha\", model, section, c_name, ref_no, part_no, description.strip(), remarks.strip(), image_id])\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\n",
    "        'pdf_id', 'year', 'brand', 'model', 'section', 'component_name',\n",
    "        'ref_no', 'part_no', 'description', 'remarks', 'image_id'\n",
    "    ])\n",
    "\n",
    "# ---------- MAIN PROCESS ----------\n",
    "def yamaha_data_extraction(pdf_path):\n",
    "\n",
    "    pdf_id = extract_pdf_id(pdf_path)\n",
    "    year = extract_year(pdf_path)\n",
    "    model = extract_model(pdf_path)\n",
    "\n",
    "    SessionLocal = sessionmaker(bind=engine)\n",
    "    session = SessionLocal()\n",
    "    try:\n",
    "        df_images = extract_images_with_fig_labels(pdf_path, pdf_id, engine)\n",
    "        image_message = f\"[INFO] Inserted {len(df_images)} new images for '{pdf_id}'.\"\n",
    "        if not df_images.empty:\n",
    "            df_images.to_sql(\"parts_images\", engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "            print(image_message)\n",
    "        else:\n",
    "            print(image_message + f\" All images for '{pdf_id}' already exist.\")\n",
    "\n",
    "        # Step 2: Check if parts data already exists\n",
    "        existing = session.execute(\n",
    "            select(1).select_from(master_parts_list).where(master_parts_list.c.pdf_id == pdf_id)\n",
    "        ).first()\n",
    "\n",
    "        if existing:\n",
    "            print(f\"[INFO] Master Parts data for '{pdf_id}' already exists.\")\n",
    "            return\n",
    "\n",
    "    finally:\n",
    "        session.close()\n",
    "            \n",
    "    # Step 3: Extract and process parts data (outside session scope)\n",
    "    all_text = extract_text_from_pdf(pdf_path)\n",
    "    df_parts = yamaha_process_data(all_text, pdf_id, year, model, num_model=3)\n",
    "\n",
    "    if not df_parts.empty:\n",
    "        #print(df_parts.to_string(index=False))\n",
    "        df_parts.to_sql(\"master_parts_list\", engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "        print(f\"[INFO] Inserted parts data for '{pdf_id}'.\")\n",
    "    else:\n",
    "        print(f\"[INFO] Error, no parts data extracted for '{pdf_id}'.\")\n",
    "\n",
    "brand = \"Yamaha\"\n",
    "supported_brands = ['Yamaha', 'Honda']\n",
    "\n",
    "if brand in supported_brands:\n",
    "    if brand == \"Yamaha\":\n",
    "        yamaha_data_extraction(pdf_path)\n",
    "    elif brand == \"Honda\":\n",
    "        print(\"Hi\")\n",
    "else:\n",
    "    print (f'\"{brand}\" not supported \\nAvailable Brands: {supported_brands}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dcaa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Reference) Original Image Extraction Code\n",
    "\n",
    "from PIL import ImageOps\n",
    "\n",
    "def normalize_image_background(image_bytes):\n",
    "    img = Image.open(BytesIO(image_bytes)).convert(\"L\")  # Convert to grayscale\n",
    "    mean_brightness = sum(img.getdata()) / (img.width * img.height)\n",
    "\n",
    "    if mean_brightness < 128:  # Likely white lines on dark background\n",
    "        img = ImageOps.invert(img)\n",
    "\n",
    "    img = img.convert(\"RGB\")  # Convert back to RGB\n",
    "\n",
    "    # Save to bytes\n",
    "    output = BytesIO()\n",
    "    img.save(output, format=\"PNG\")\n",
    "    return output.getvalue()\n",
    "\n",
    "def extract_images_with_fig_labels(pdf_path, pdf_id):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    data = []\n",
    "    seen_figs = set()\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "\n",
    "        matches = re.findall(r\"FIG\\.\\s*([\\w-]+)\", text)\n",
    "        if not matches:\n",
    "            continue\n",
    "\n",
    "        fig_no = matches[0]\n",
    "        if fig_no in seen_figs:\n",
    "            continue\n",
    "\n",
    "        image_list = page.get_images(full=True)\n",
    "        if not image_list:\n",
    "            continue\n",
    "\n",
    "        xref = image_list[0][0]\n",
    "        base_image = doc.extract_image(xref)\n",
    "\n",
    "        # âœ… Normalize background here\n",
    "        image = normalize_image_background(base_image[\"image\"])\n",
    "\n",
    "        data.append({\n",
    "            \"pdf_id\": pdf_id,\n",
    "            \"fig_no\": fig_no,\n",
    "            \"image\": image\n",
    "        })\n",
    "        seen_figs.add(fig_no)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Function to resize and display images from DataFrame\n",
    "def display_resized_image(image, size=(100, 100)):  # Resize to 100x100\n",
    "    img = Image.open(BytesIO(image))  # Open image from bytes\n",
    "    img.thumbnail(size)  # Resize while maintaining aspect ratio\n",
    "\n",
    "    # Save to a byte stream in PNG format\n",
    "    byte_io = BytesIO()\n",
    "    img.save(byte_io, format='PNG')\n",
    "    byte_io.seek(0)  # Ensure we're at the start of the byte stream\n",
    "\n",
    "    # Show the resized image as a PNG\n",
    "    display(IPImage(data=byte_io.read(), format='png'))\n",
    "\n",
    "# Updated part to display images with a small size\n",
    "def show_images_in_df(df):\n",
    "    for idx, row in df.iterrows():\n",
    "        fig_no = row['fig_no']\n",
    "        print(f\"Displaying image for FIG. {fig_no}\")\n",
    "        display_resized_image(row['image'], size=(100, 100))  # Resize image to 100x100\n",
    "\n",
    "# 1. Function to get existing (pdf_id, fig_no) pairs from DB\n",
    "def get_existing_fig_combos(engine, pdf_id):\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(\n",
    "            text(\"SELECT fig_no FROM parts_images WHERE pdf_id = :pdf_id\"),\n",
    "            {\"pdf_id\": pdf_id}\n",
    "        )\n",
    "        return set(str(row[0]) for row in result.fetchall())  # Cast to str for consistent comparison\n",
    "\n",
    "# 2. Main processing function\n",
    "def main(pdf_path):\n",
    "    pdf_id = extract_pdf_id(pdf_path)\n",
    "    df = extract_images_with_fig_labels(pdf_path, pdf_id)\n",
    "    show_images_in_df(df.head(5))\n",
    "    # Ensure fig_no is string for comparison\n",
    "    df[\"fig_no\"] = df[\"fig_no\"].astype(str)\n",
    "\n",
    "    print(f\"Found {len(df)} images in PDF: {pdf_path}\")\n",
    "\n",
    "    # Get existing combos from the DB\n",
    "    existing_figs = get_existing_fig_combos(engine, pdf_id)\n",
    "\n",
    "    # Filter only new fig_no entries\n",
    "    df = df[~df[\"fig_no\"].isin(existing_figs)]\n",
    "\n",
    "    print(f\"{len(df)} new images to insert.\")\n",
    "    \n",
    "    # Show first few images\n",
    "    if not df.empty:\n",
    "        print(df.head(5).to_string(index=False))\n",
    "        # Insert into database\n",
    "        #df.to_sql(\"parts_images\", engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "        print(\"Insertion complete.\")\n",
    "    else:\n",
    "        print(\"No new images to insert.\")\n",
    "\n",
    "main(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e3324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Reference) Original Function to extract text from the PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    all_text = \"\"\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        # Iterate over all pages (for the whole manual)\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text() or \"\"\n",
    "            lines = text.split('\\n')\n",
    "            first_line = lines[0].strip() if lines else \"\"\n",
    "\n",
    "            # Skip pages with no spare parts data (pages without FIG.)\n",
    "            if not any(\"FIG.\" in line for line in lines):\n",
    "                continue\n",
    "\n",
    "            # Stop if numerical index is reached\n",
    "            if \"NUMERICAL INDEX\" in first_line:\n",
    "                print(f\"Found 'NUMERICAL INDEX' on page {page_num + 1}. Stopping further processing.\")\n",
    "                break\n",
    "\n",
    "            # Accumulate text from valid pages\n",
    "            all_text += f\"\\n--- Page {page_num + 1} ---\\n{text}\\n\"\n",
    "    \n",
    "    return all_text\n",
    "\n",
    "# Process function now accepts a pdf_id as argument\n",
    "def process_data(text, pdf_id, year, num_model=3):\n",
    "    rows = []\n",
    "    lines = text.strip().split('\\n')\n",
    "\n",
    "    # Initialize columns for data collection\n",
    "    fig_no = \"\"\n",
    "    c_name = \"\"\n",
    "    prev_fig_no = \"\"\n",
    "    prev_c_name = \"\"\n",
    "    prev_ref_no = \"\"\n",
    "    collect_data = False\n",
    "\n",
    "    for line_num, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Detect if page is a Parts Information pages then stores Fig Num and Component Name\n",
    "        if line.startswith('FIG.'):\n",
    "            tokens = line.split()\n",
    "            if len(tokens) >= 3:\n",
    "                fig_no = tokens[1]\n",
    "                c_name = \" \".join(tokens[2:])\n",
    "                prev_fig_no = fig_no\n",
    "                prev_c_name = c_name\n",
    "                collect_data = True\n",
    "            continue\n",
    "\n",
    "        # Safety Net 1: Skip lines until valid data table starts\n",
    "        if not collect_data:\n",
    "            continue\n",
    "\n",
    "        # Safety Net 2: Use previous figure number and component name if not explicitly found in the current line\n",
    "        if not fig_no:\n",
    "            fig_no = prev_fig_no\n",
    "            c_name = prev_c_name\n",
    "\n",
    "        parts = line.split()\n",
    "    \n",
    "        # Allow data to be collected even if ref_no is missing\n",
    "        is_valid_data_line = (\n",
    "            len(parts) >= 2 and  # Check if the line has at least part number and description\n",
    "            (re.match(r'\\w+[-â€“]\\w+', parts[0]) or re.match(r'\\d+', parts[0]))  # Check if first part is a valid part number or ref number\n",
    "        )\n",
    "\n",
    "        if not is_valid_data_line:\n",
    "            continue\n",
    "\n",
    "        # Determine ref_no and part_no\n",
    "        if parts[0].isdigit():\n",
    "            ref_no = parts[0]\n",
    "            part_no = parts[1]\n",
    "            rest = parts[2:] # Description + Quantity + Remarks\n",
    "            prev_ref_no = ref_no\n",
    "        else:\n",
    "            ref_no = prev_ref_no\n",
    "            part_no = parts[0]\n",
    "            rest = parts[1:] # Description + Quantity + Remarks\n",
    "\n",
    "        rest = \" \".join(rest).split()\n",
    "\n",
    "        description = \"\"\n",
    "        remarks = \"\"\n",
    "        numbers = []\n",
    "        found_numbers = False\n",
    "\n",
    "        for item in rest:\n",
    "            if item.isdigit():\n",
    "                numbers.append(item)\n",
    "                found_numbers = True\n",
    "                continue\n",
    "            if not found_numbers:\n",
    "                description += item + \" \"\n",
    "            else:\n",
    "                remarks += item + \" \"\n",
    "        \n",
    "        if len(numbers) > num_model:\n",
    "            description += numbers[0]\n",
    "        \n",
    "        description = description.strip()\n",
    "        remarks = remarks.strip()\n",
    "\n",
    "        # Append pdf_id and year along with the rest of the data\n",
    "        rows.append([pdf_id, year, \"Yamaha\", fig_no, c_name, ref_no, part_no, description, remarks])\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        rows,\n",
    "        columns=['pdf_id', 'year', 'brand', 'fig_no', 'component_name', 'ref_no', 'part_no', 'description', 'remarks']\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Extract the first part of the filename (before any year or bracketed sections)\n",
    "def extract_pdf_id(pdf_path):\n",
    "    # Extract the base filename without the extension\n",
    "    base_filename = os.path.basename(pdf_path).split('.')[0]\n",
    "    \n",
    "    # Match the first part before any year or parentheses, i.e., extract 'AEROX 155' or 'FJR1300A'\n",
    "    match = re.match(r\"([A-Za-z0-9 ]+)\", base_filename)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1).strip()  # Return the matched pdf_id, cleaned of extra spaces\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Extract year from the filename (if available)\n",
    "def extract_year(pdf_path):\n",
    "    year_match = re.search(r\"'(\\d{2})\", pdf_path)\n",
    "    if year_match:\n",
    "        return f\"20{year_match.group(1)}\"  # Convert '15' to '2015'\n",
    "    else:\n",
    "        return None  # If no year is found, set it to None\n",
    "\n",
    "# Main function to process PDF\n",
    "def main(pdf_path):\n",
    "    # Extract pdf_id and year\n",
    "    pdf_id = extract_pdf_id(pdf_path)\n",
    "    year = extract_year(pdf_path)\n",
    "\n",
    "    # Extract all text from the PDF\n",
    "    all_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    # Process the extracted text to generate structured data\n",
    "    df = process_data(all_text, pdf_id, year)\n",
    "\n",
    "    # Display the structured table\n",
    "    print(df.to_string(index=False))\n",
    "\n",
    "    # Adding data to Database\n",
    "    df.to_sql(\"master_parts_list\", engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "\n",
    "# Run the main function\n",
    "main(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d20a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inserted 0 new images for 'FJR1300A'. All images for 'FJR1300A' already exist.\n",
      "[INFO] Master Parts data for 'FJR1300A' already exists.\n"
     ]
    }
   ],
   "source": [
    "#Final Working VER\n",
    "\n",
    "# Test\n",
    "# ---------- HELPERS ----------\n",
    "def extract_pdf_id(pdf_path):\n",
    "    base_filename = os.path.basename(pdf_path).split('.')[0]\n",
    "    match = re.match(r\"([A-Za-z0-9 ]+)\", base_filename)\n",
    "    if match:\n",
    "        return match.group(1).replace(\" \", \"\")  # Remove all spaces\n",
    "    return None\n",
    "\n",
    "def extract_year(pdf_path):\n",
    "    year_match = re.search(r\"'(\\d{2})\", pdf_path)\n",
    "    return f\"20{year_match.group(1)}\" if year_match else None\n",
    "\n",
    "def extract_model(pdf_path):\n",
    "    base_filename = os.path.basename(pdf_path)\n",
    "    match = re.search(r\"\\((.*?)\\)\", base_filename)\n",
    "    if match:\n",
    "        return match.group(1)  # e.g., \"B65P, B65R, B65S\"\n",
    "    return None\n",
    "\n",
    "# ---------- IMAGE EXTRACTION ----------\n",
    "def normalize_image_background(image_bytes):\n",
    "    img = Image.open(BytesIO(image_bytes)).convert(\"L\")  # Grayscale\n",
    "    mean_brightness = sum(img.getdata()) / (img.width * img.height)\n",
    "\n",
    "    if mean_brightness < 128:  # Invert if it's a dark background\n",
    "        img = ImageOps.invert(img)\n",
    "\n",
    "    img = img.convert(\"RGB\")  # Convert back to RGB\n",
    "\n",
    "    output = BytesIO()\n",
    "    img.save(output, format=\"PNG\")\n",
    "    return output.getvalue()\n",
    "\n",
    "def extract_images_with_fig_labels(pdf_path, pdf_id, engine):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    data = []\n",
    "\n",
    "    # Step 1: Get existing (pdf_id, fig_no) combos from DB\n",
    "    existing_figs = get_existing_fig_combos(engine, pdf_id)\n",
    "\n",
    "    seen_figs = set()  # Track unique figs within the PDF\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "\n",
    "        matches = re.findall(r\"FIG\\.\\s*([\\w-]+)\", text)\n",
    "        if not matches:\n",
    "            continue\n",
    "\n",
    "        fig_no = matches[0]\n",
    "\n",
    "        if fig_no in seen_figs or fig_no in existing_figs:\n",
    "            continue  # Skip if already handled or exists in DB\n",
    "\n",
    "        image_list = page.get_images(full=True)\n",
    "        if not image_list:\n",
    "            continue\n",
    "\n",
    "        xref = image_list[0][0]\n",
    "        base_image = doc.extract_image(xref)\n",
    "        image = normalize_image_background(base_image[\"image\"])\n",
    "\n",
    "        image_id = \"_\".join([pdf_id, fig_no])\n",
    "\n",
    "        data.append({\n",
    "            \"image_id\" : image_id,\n",
    "            \"pdf_id\": pdf_id,\n",
    "            \"fig_no\": fig_no,\n",
    "            \"image\": image\n",
    "        })\n",
    "        seen_figs.add(fig_no)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def get_existing_fig_combos(engine, pdf_id):\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(\n",
    "            text(\"SELECT fig_no FROM parts_images WHERE pdf_id = :pdf_id\"),\n",
    "            {\"pdf_id\": pdf_id}\n",
    "        )\n",
    "        return set(str(row[0]) for row in result.fetchall())  # Cast to str for consistent comparison\n",
    "\n",
    "# ---------- TEXT EXTRACTION ----------\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    all_text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text() or \"\"\n",
    "            lines = text.split('\\n')\n",
    "            first_line = lines[0].strip() if lines else \"\"\n",
    "            if not any(\"FIG.\" in line for line in lines):\n",
    "                continue\n",
    "            if \"NUMERICAL INDEX\" in first_line:\n",
    "                break\n",
    "            all_text += f\"\\n--- Page {page_num + 1} ---\\n{text}\\n\"\n",
    "    return all_text\n",
    "\n",
    "def yamaha_process_data(text, pdf_id, year, model, num_model):\n",
    "    rows = []\n",
    "    lines = text.strip().split('\\n')\n",
    "    section = c_name = prev_fig_no = prev_c_name = prev_ref_no = \"\"\n",
    "    collect_data = False\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line: continue\n",
    "        if line.startswith('FIG.'):\n",
    "            tokens = line.split()\n",
    "            if len(tokens) >= 3:\n",
    "                section = tokens[1]\n",
    "                c_name = \" \".join(tokens[2:])\n",
    "                prev_fig_no, prev_c_name = section, c_name\n",
    "                collect_data = True\n",
    "            continue\n",
    "        if not collect_data: continue\n",
    "        if not section:\n",
    "            section, c_name = prev_fig_no, prev_c_name\n",
    "\n",
    "        parts = line.split()\n",
    "        is_valid_data_line = (\n",
    "            len(parts) >= 2 and \n",
    "            (re.match(r'\\w+[-â€“]\\w+', parts[0]) or parts[0].isdigit())\n",
    "        )\n",
    "        if not is_valid_data_line:\n",
    "            continue\n",
    "\n",
    "        if parts[0].isdigit():\n",
    "            ref_no = parts[0]\n",
    "            part_no = parts[1]\n",
    "            rest = parts[2:]\n",
    "            prev_ref_no = ref_no\n",
    "        else:\n",
    "            ref_no = prev_ref_no\n",
    "            part_no = parts[0]\n",
    "            rest = parts[1:]\n",
    "\n",
    "        rest = \" \".join(rest).split()\n",
    "        description = remarks = \"\"\n",
    "        numbers = []\n",
    "        found_numbers = False\n",
    "        for item in rest:\n",
    "            if item.isdigit():\n",
    "                numbers.append(item)\n",
    "                found_numbers = True\n",
    "                continue\n",
    "            if not found_numbers:\n",
    "                description += item + \" \"\n",
    "            else:\n",
    "                remarks += item + \" \"\n",
    "        if len(numbers) > num_model:\n",
    "            description += numbers[0]\n",
    "\n",
    "        image_id = \"_\".join([pdf_id, section])\n",
    "\n",
    "        rows.append([pdf_id, year, \"Yamaha\", model, section, c_name, ref_no, part_no, description.strip(), remarks.strip(), image_id])\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\n",
    "        'pdf_id', 'year', 'brand', 'model', 'section', 'component_name',\n",
    "        'ref_no', 'part_no', 'description', 'remarks', 'image_id'\n",
    "    ])\n",
    "\n",
    "# ---------- MAIN PROCESS ----------\n",
    "def yamaha_data_extraction(pdf_path):\n",
    "\n",
    "    pdf_id = extract_pdf_id(pdf_path)\n",
    "    year = extract_year(pdf_path)\n",
    "    model = extract_model(pdf_path)\n",
    "\n",
    "    SessionLocal = sessionmaker(bind=engine)\n",
    "    session = SessionLocal()\n",
    "    try:\n",
    "        df_images = extract_images_with_fig_labels(pdf_path, pdf_id, engine)\n",
    "        image_message = f\"[INFO] Inserted {len(df_images)} new images for '{pdf_id}'.\"\n",
    "        if not df_images.empty:\n",
    "            df_images.to_sql(\"parts_images\", engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "            print(image_message)\n",
    "        else:\n",
    "            print(image_message + f\" All images for '{pdf_id}' already exist.\")\n",
    "\n",
    "        # Step 2: Check if parts data already exists\n",
    "        existing = session.execute(\n",
    "            select(1).select_from(master_parts_list).where(master_parts_list.c.pdf_id == pdf_id)\n",
    "        ).first()\n",
    "\n",
    "        if existing:\n",
    "            print(f\"[INFO] Master Parts data for '{pdf_id}' already exists.\")\n",
    "            return\n",
    "\n",
    "    finally:\n",
    "        session.close()\n",
    "            \n",
    "    # Step 3: Extract and process parts data (outside session scope)\n",
    "    all_text = extract_text_from_pdf(pdf_path)\n",
    "    df_parts = yamaha_process_data(all_text, pdf_id, year, model, num_model=3)\n",
    "\n",
    "    if not df_parts.empty:\n",
    "        #print(df_parts.to_string(index=False))\n",
    "        df_parts.to_sql(\"master_parts_list\", engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "        print(f\"[INFO] Inserted parts data for '{pdf_id}'.\")\n",
    "    else:\n",
    "        print(f\"[INFO] Error, no parts data extracted for '{pdf_id}'.\")\n",
    "\n",
    "brand = \"Yamaha\"\n",
    "supported_brands = ['Yamaha', 'Honda']\n",
    "\n",
    "if brand in supported_brands:\n",
    "    if brand == \"Yamaha\":\n",
    "        yamaha_data_extraction(pdf_path)\n",
    "    elif brand == \"Honda\":\n",
    "        print(\"Hi\")\n",
    "else:\n",
    "    print (f'\"{brand}\" not supported \\nAvailable Brands: {supported_brands}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a2b6ef",
   "metadata": {},
   "source": [
    "### Week 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6796366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
