{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "346b35a4",
   "metadata": {},
   "source": [
    "### Week 1-2: Requirement Analysis & Tech Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1898623c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Natha\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# streamlit: Web app framework (No html/css required)\n",
    "# openai: OpenAI API wrapper\n",
    "# faiss-cpu: Vector Database\n",
    "# langchain: LLM wrapper\n",
    "# opencv-python: Image processing\n",
    "# pandas: Data manipulation\n",
    "# sqlalchemy: Database connection\n",
    "\n",
    "import openai\n",
    "import faiss\n",
    "import langchain\n",
    "import pandas as pd\n",
    "from sqlalchemy import (\n",
    "    select, create_engine, Table, Column, Integer, String, MetaData,\n",
    "    ForeignKey, ForeignKeyConstraint, UniqueConstraint, LargeBinary, text\n",
    ")\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "# PyMuPDF, pdfplumber, or OCR\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "import re\n",
    "import pdfplumber\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# For Image Display within the df\n",
    "from IPython.display import display, Image\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import display, Image as IPImage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40a3a43",
   "metadata": {},
   "source": [
    "### Connected to PostgreSQL, Created Database, Store Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4e07f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seting up connection and importing libraries\n",
    "from sqlalchemy import (\n",
    "    create_engine, Table, Column, Integer, String, MetaData,\n",
    "    ForeignKeyConstraint, UniqueConstraint\n",
    ")\n",
    "\n",
    "# Replace values with your actual database info\n",
    "username = \"postgres\"\n",
    "password = \"MPAMS\"\n",
    "host = \"localhost\"\n",
    "port = \"5432\"\n",
    "database = \"MPDB\"\n",
    "\n",
    "\n",
    "# SQLAlchemy connection URL\n",
    "DATABASE_URL = f\"postgresql://{username}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "# Create engine\n",
    "engine = create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0628c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the 2 tables\n",
    "metadata = MetaData()\n",
    "\n",
    "master_parts_list = Table(\n",
    "    \"master_parts_list\", metadata,\n",
    "    Column(\"mpl_id\", Integer, primary_key=True),\n",
    "    Column(\"pdf_id\", String, nullable=False),\n",
    "    Column(\"year\", Integer, nullable=False),\n",
    "    Column(\"brand\", String, nullable=False),\n",
    "    Column(\"fig_no\", Integer, nullable=False),\n",
    "    Column(\"component_name\", String, nullable=False),\n",
    "    Column(\"ref_no\", Integer, nullable=False),\n",
    "    Column(\"part_no\", String, nullable=False),\n",
    "    Column(\"description\", String, nullable=False),\n",
    "    Column(\"remarks\", String),\n",
    "    Column(\"image_id\", String, ForeignKey(\"parts_images.image_id\", ondelete=\"SET NULL\"))\n",
    ")\n",
    "\n",
    "parts_images = Table(\n",
    "    \"parts_images\", metadata,\n",
    "    Column(\"image_id\", String, primary_key=True),\n",
    "    Column(\"pdf_id\", String, nullable=False),\n",
    "    Column(\"fig_no\", Integer, nullable=False),\n",
    "    Column(\"image\", LargeBinary, nullable=False),\n",
    ")\n",
    "\n",
    "# Create the tables\n",
    "metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ab4148",
   "metadata": {},
   "source": [
    "### Week 3: Inventory Data Extraction & Indexing (2a–2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0935ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse PDFs (Use PyMuPDF, pdfplumber, or OCR)\n",
    "# Store structured data in a relevant data warehouse or database (e.g., SQLite/PostgreSQL).\n",
    "# Use vector embeddings and FAISS to enable semantic search and RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a9f13bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format 1: Yamaha\n",
    "# Important images from page 6-60\n",
    "pdf_1 = \"Manuals/AEROX 155 '19 (B65P, B65R, B65S).pdf\"\n",
    "pdf_2= \"Manuals/FJR1300A '15 (1MCH, 1MCG).PDF\"\n",
    "\n",
    "# Format 2: Honda\n",
    "pdf_3 = \"Manuals/CRF1000 A_PC_13MJPG02_(G.H).pdf\"\n",
    "pdf_4 = \"Manuals/NC750XAP_13MKWM02_PC_2022_2023.pdf\"\n",
    "\n",
    "pdf_path = pdf_2\n",
    "\n",
    "# Set the start and end page numbers (1-based index)\n",
    "start_page = 23  # for example, page 6\n",
    "end_page = 23 # for example, only page 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3199ccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Toyota\" not supported \n",
      "Available Brands: ['Yamaha', 'Honda']\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "# ---------- HELPERS ----------\n",
    "def extract_pdf_id(pdf_path):\n",
    "    base_filename = os.path.basename(pdf_path).split('.')[0]\n",
    "    match = re.match(r\"([A-Za-z0-9 ]+)\", base_filename)\n",
    "    if match:\n",
    "        return match.group(1).replace(\" \", \"\")  # Remove all spaces\n",
    "    return None\n",
    "\n",
    "def extract_year(pdf_path):\n",
    "    year_match = re.search(r\"'(\\d{2})\", pdf_path)\n",
    "    return f\"20{year_match.group(1)}\" if year_match else None\n",
    "\n",
    "# ---------- IMAGE EXTRACTION ----------\n",
    "def extract_images_with_fig_labels(pdf_path, pdf_id, engine):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    data = []\n",
    "\n",
    "    # Step 1: Get existing (pdf_id, fig_no) combos from DB\n",
    "    existing_figs = get_existing_fig_combos(engine, pdf_id)\n",
    "\n",
    "    seen_figs = set()  # Track unique figs within the PDF\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "\n",
    "        matches = re.findall(r\"FIG\\.\\s*([\\w-]+)\", text)\n",
    "        if not matches:\n",
    "            continue\n",
    "\n",
    "        fig_no = matches[0]\n",
    "\n",
    "        if fig_no in seen_figs or fig_no in existing_figs:\n",
    "            continue  # Skip if already handled or exists in DB\n",
    "\n",
    "        image_list = page.get_images(full=True)\n",
    "        if not image_list:\n",
    "            continue\n",
    "\n",
    "        xref = image_list[0][0]\n",
    "        base_image = doc.extract_image(xref)\n",
    "        image = base_image[\"image\"]\n",
    "\n",
    "        image_id = \"_\".join([pdf_id, fig_no])\n",
    "\n",
    "        data.append({\n",
    "            \"image_id\" : image_id,\n",
    "            \"pdf_id\": pdf_id,\n",
    "            \"fig_no\": fig_no,\n",
    "            \"image\": image\n",
    "        })\n",
    "        seen_figs.add(fig_no)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def get_existing_fig_combos(engine, pdf_id):\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(\n",
    "            text(\"SELECT fig_no FROM parts_images WHERE pdf_id = :pdf_id\"),\n",
    "            {\"pdf_id\": pdf_id}\n",
    "        )\n",
    "        return set(str(row[0]) for row in result.fetchall())  # Cast to str for consistent comparison\n",
    "\n",
    "# ---------- TEXT EXTRACTION ----------\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    all_text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text() or \"\"\n",
    "            lines = text.split('\\n')\n",
    "            first_line = lines[0].strip() if lines else \"\"\n",
    "            if not any(\"FIG.\" in line for line in lines):\n",
    "                continue\n",
    "            if \"NUMERICAL INDEX\" in first_line:\n",
    "                break\n",
    "            all_text += f\"\\n--- Page {page_num + 1} ---\\n{text}\\n\"\n",
    "    return all_text\n",
    "\n",
    "def yamaha_process_data(text, pdf_id, year, num_model):\n",
    "    rows = []\n",
    "    lines = text.strip().split('\\n')\n",
    "    fig_no = c_name = prev_fig_no = prev_c_name = prev_ref_no = \"\"\n",
    "    collect_data = False\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line: continue\n",
    "        if line.startswith('FIG.'):\n",
    "            tokens = line.split()\n",
    "            if len(tokens) >= 3:\n",
    "                fig_no = tokens[1]\n",
    "                c_name = \" \".join(tokens[2:])\n",
    "                prev_fig_no, prev_c_name = fig_no, c_name\n",
    "                collect_data = True\n",
    "            continue\n",
    "        if not collect_data: continue\n",
    "        if not fig_no:\n",
    "            fig_no, c_name = prev_fig_no, prev_c_name\n",
    "\n",
    "        parts = line.split()\n",
    "        is_valid_data_line = (\n",
    "            len(parts) >= 2 and \n",
    "            (re.match(r'\\w+[-–]\\w+', parts[0]) or parts[0].isdigit())\n",
    "        )\n",
    "        if not is_valid_data_line:\n",
    "            continue\n",
    "\n",
    "        if parts[0].isdigit():\n",
    "            ref_no = parts[0]\n",
    "            part_no = parts[1]\n",
    "            rest = parts[2:]\n",
    "            prev_ref_no = ref_no\n",
    "        else:\n",
    "            ref_no = prev_ref_no\n",
    "            part_no = parts[0]\n",
    "            rest = parts[1:]\n",
    "\n",
    "        rest = \" \".join(rest).split()\n",
    "        description = remarks = \"\"\n",
    "        numbers = []\n",
    "        found_numbers = False\n",
    "        for item in rest:\n",
    "            if item.isdigit():\n",
    "                numbers.append(item)\n",
    "                found_numbers = True\n",
    "                continue\n",
    "            if not found_numbers:\n",
    "                description += item + \" \"\n",
    "            else:\n",
    "                remarks += item + \" \"\n",
    "        if len(numbers) > num_model:\n",
    "            description += numbers[0]\n",
    "\n",
    "        image_id = \"_\".join([pdf_id, fig_no])\n",
    "\n",
    "        rows.append([pdf_id, year, \"Yamaha\", fig_no, c_name, ref_no, part_no, description.strip(), remarks.strip(), image_id])\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\n",
    "        'pdf_id', 'year', 'brand', 'fig_no', 'component_name',\n",
    "        'ref_no', 'part_no', 'description', 'remarks', 'image_id'\n",
    "    ])\n",
    "\n",
    "# ---------- MAIN PROCESS ----------\n",
    "def yamaha_data_extraction(pdf_path):\n",
    "\n",
    "    pdf_id = extract_pdf_id(pdf_path)\n",
    "    year = extract_year(pdf_path)\n",
    "\n",
    "    with Session(engine) as session:\n",
    "        df_images = extract_images_with_fig_labels(pdf_path, pdf_id, engine)\n",
    "        image_message = f\"[INFO] Inserted {len(df_images)} new images for '{pdf_id}'.\"\n",
    "        if not df_images.empty:\n",
    "            df_images.to_sql(\"parts_images\", engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "            print(image_message)\n",
    "        else:\n",
    "            print(image_message + f\" All images for '{pdf_id}' already exist.\")\n",
    "\n",
    "        # Step 2: Check if parts data already exists\n",
    "        existing = session.execute(\n",
    "            select(1).select_from(master_parts_list).where(master_parts_list.c.pdf_id == pdf_id)\n",
    "        ).first()\n",
    "\n",
    "        if existing:\n",
    "            print(f\"[INFO] Master Parts data for '{pdf_id}' already exists.\")\n",
    "            return\n",
    "            \n",
    "    # Step 3: Extract and process parts data (outside session scope)\n",
    "    all_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    df_parts = yamaha_process_data(all_text, pdf_id, year, num_model=3)\n",
    "\n",
    "    if not df_parts.empty:\n",
    "        df_parts.to_sql(\"master_parts_list\", engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "        print(f\"[INFO] Inserted parts data for '{pdf_id}'.\")\n",
    "    else:\n",
    "        print(f\"[INFO] Error, no parts data extracted for '{pdf_id}'.\")\n",
    "\n",
    "brand = input(\"Brand?\")\n",
    "supported_brands = ['Yamaha', 'Honda']\n",
    "\n",
    "if brand in supported_brands:\n",
    "    if brand == \"Yamaha\":\n",
    "        yamaha_data_extraction(pdf_path)\n",
    "    elif brand == \"Honda\":\n",
    "        print(\"Nigger\")\n",
    "else:\n",
    "    print (f'\"{brand}\" not supported \\nAvailable Brands: {supported_brands}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dcaa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Reference) Original Image Extraction Code\n",
    "\n",
    "# Function to extract text and name images based on FIG. numbers\n",
    "def extract_images_with_fig_labels(pdf_path, pdf_id):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    data = []\n",
    "    seen_figs = set()  # Track unique figure numbers\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "\n",
    "        # Extract FIG. number from text\n",
    "        matches = re.findall(r\"FIG\\.\\s*([\\w-]+)\", text)\n",
    "        if not matches:\n",
    "            continue  # Skip pages without FIG.\n",
    "\n",
    "        fig_no = matches[0]  # Use first FIG. number\n",
    "\n",
    "        # Skip if this figure has already been added\n",
    "        if fig_no in seen_figs:\n",
    "            continue\n",
    "\n",
    "        # Extract images from the page\n",
    "        image_list = page.get_images(full=True)\n",
    "        if not image_list:\n",
    "            continue  # Skip if no images\n",
    "\n",
    "        # Get the first image (you can extend to handle more if needed)\n",
    "        xref = image_list[0][0]\n",
    "        base_image = doc.extract_image(xref)\n",
    "        image = base_image[\"image\"]\n",
    "\n",
    "        # Add to the list and mark this fig as seen\n",
    "        data.append({\n",
    "            \"pdf_id\": pdf_id,\n",
    "            \"fig_no\": fig_no,\n",
    "            \"image\": image\n",
    "        })\n",
    "        seen_figs.add(fig_no)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Function to resize and display images from DataFrame\n",
    "def display_resized_image(image, size=(100, 100)):  # Resize to 100x100\n",
    "    img = Image.open(BytesIO(image))  # Open image from bytes\n",
    "    img.thumbnail(size)  # Resize while maintaining aspect ratio\n",
    "\n",
    "    # Save to a byte stream in PNG format\n",
    "    byte_io = BytesIO()\n",
    "    img.save(byte_io, format='PNG')\n",
    "    byte_io.seek(0)  # Ensure we're at the start of the byte stream\n",
    "\n",
    "    # Show the resized image as a PNG\n",
    "    display(IPImage(data=byte_io.read(), format='png'))\n",
    "\n",
    "# Updated part to display images with a small size\n",
    "def show_images_in_df(df):\n",
    "    for idx, row in df.iterrows():\n",
    "        fig_no = row['fig_no']\n",
    "        print(f\"Displaying image for FIG. {fig_no}\")\n",
    "        display_resized_image(row['image'], size=(100, 100))  # Resize image to 100x100\n",
    "\n",
    "# 1. Function to get existing (pdf_id, fig_no) pairs from DB\n",
    "def get_existing_fig_combos(engine, pdf_id):\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(\n",
    "            text(\"SELECT fig_no FROM parts_images WHERE pdf_id = :pdf_id\"),\n",
    "            {\"pdf_id\": pdf_id}\n",
    "        )\n",
    "        return set(str(row[0]) for row in result.fetchall())  # Cast to str for consistent comparison\n",
    "\n",
    "# 2. Main processing function\n",
    "def main(pdf_path):\n",
    "    pdf_id = extract_pdf_id(pdf_path)\n",
    "    df = extract_images_with_fig_labels(pdf_path, pdf_id)\n",
    "\n",
    "    # Ensure fig_no is string for comparison\n",
    "    df[\"fig_no\"] = df[\"fig_no\"].astype(str)\n",
    "\n",
    "    print(f\"Found {len(df)} images in PDF: {pdf_path}\")\n",
    "\n",
    "    # Get existing combos from the DB\n",
    "    existing_figs = get_existing_fig_combos(engine, pdf_id)\n",
    "\n",
    "    # Filter only new fig_no entries\n",
    "    df = df[~df[\"fig_no\"].isin(existing_figs)]\n",
    "\n",
    "    print(f\"{len(df)} new images to insert.\")\n",
    "\n",
    "    # Show first few images\n",
    "    if not df.empty:\n",
    "        print(df.head(5).to_string(index=False))\n",
    "        show_images_in_df(df)\n",
    "\n",
    "        # Insert into database\n",
    "        df.to_sql(\"parts_images\", engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "        print(\"Insertion complete.\")\n",
    "    else:\n",
    "        print(\"No new images to insert.\")\n",
    "\n",
    "main(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e3324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Reference) Original Function to extract text from the PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    all_text = \"\"\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        # Iterate over all pages (for the whole manual)\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text() or \"\"\n",
    "            lines = text.split('\\n')\n",
    "            first_line = lines[0].strip() if lines else \"\"\n",
    "\n",
    "            # Skip pages with no spare parts data (pages without FIG.)\n",
    "            if not any(\"FIG.\" in line for line in lines):\n",
    "                continue\n",
    "\n",
    "            # Stop if numerical index is reached\n",
    "            if \"NUMERICAL INDEX\" in first_line:\n",
    "                print(f\"Found 'NUMERICAL INDEX' on page {page_num + 1}. Stopping further processing.\")\n",
    "                break\n",
    "\n",
    "            # Accumulate text from valid pages\n",
    "            all_text += f\"\\n--- Page {page_num + 1} ---\\n{text}\\n\"\n",
    "    \n",
    "    return all_text\n",
    "\n",
    "# Process function now accepts a pdf_id as argument\n",
    "def process_data(text, pdf_id, year, num_model=3):\n",
    "    rows = []\n",
    "    lines = text.strip().split('\\n')\n",
    "\n",
    "    # Initialize columns for data collection\n",
    "    fig_no = \"\"\n",
    "    c_name = \"\"\n",
    "    prev_fig_no = \"\"\n",
    "    prev_c_name = \"\"\n",
    "    prev_ref_no = \"\"\n",
    "    collect_data = False\n",
    "\n",
    "    for line_num, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Detect if page is a Parts Information pages then stores Fig Num and Component Name\n",
    "        if line.startswith('FIG.'):\n",
    "            tokens = line.split()\n",
    "            if len(tokens) >= 3:\n",
    "                fig_no = tokens[1]\n",
    "                c_name = \" \".join(tokens[2:])\n",
    "                prev_fig_no = fig_no\n",
    "                prev_c_name = c_name\n",
    "                collect_data = True\n",
    "            continue\n",
    "\n",
    "        # Safety Net 1: Skip lines until valid data table starts\n",
    "        if not collect_data:\n",
    "            continue\n",
    "\n",
    "        # Safety Net 2: Use previous figure number and component name if not explicitly found in the current line\n",
    "        if not fig_no:\n",
    "            fig_no = prev_fig_no\n",
    "            c_name = prev_c_name\n",
    "\n",
    "        parts = line.split()\n",
    "    \n",
    "        # Allow data to be collected even if ref_no is missing\n",
    "        is_valid_data_line = (\n",
    "            len(parts) >= 2 and  # Check if the line has at least part number and description\n",
    "            (re.match(r'\\w+[-–]\\w+', parts[0]) or re.match(r'\\d+', parts[0]))  # Check if first part is a valid part number or ref number\n",
    "        )\n",
    "\n",
    "        if not is_valid_data_line:\n",
    "            continue\n",
    "\n",
    "        # Determine ref_no and part_no\n",
    "        if parts[0].isdigit():\n",
    "            ref_no = parts[0]\n",
    "            part_no = parts[1]\n",
    "            rest = parts[2:] # Description + Quantity + Remarks\n",
    "            prev_ref_no = ref_no\n",
    "        else:\n",
    "            ref_no = prev_ref_no\n",
    "            part_no = parts[0]\n",
    "            rest = parts[1:] # Description + Quantity + Remarks\n",
    "\n",
    "        rest = \" \".join(rest).split()\n",
    "\n",
    "        description = \"\"\n",
    "        remarks = \"\"\n",
    "        numbers = []\n",
    "        found_numbers = False\n",
    "\n",
    "        for item in rest:\n",
    "            if item.isdigit():\n",
    "                numbers.append(item)\n",
    "                found_numbers = True\n",
    "                continue\n",
    "            if not found_numbers:\n",
    "                description += item + \" \"\n",
    "            else:\n",
    "                remarks += item + \" \"\n",
    "        \n",
    "        if len(numbers) > num_model:\n",
    "            description += numbers[0]\n",
    "        \n",
    "        description = description.strip()\n",
    "        remarks = remarks.strip()\n",
    "\n",
    "        # Append pdf_id and year along with the rest of the data\n",
    "        rows.append([pdf_id, year, \"Yamaha\", fig_no, c_name, ref_no, part_no, description, remarks])\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        rows,\n",
    "        columns=['pdf_id', 'year', 'brand', 'fig_no', 'component_name', 'ref_no', 'part_no', 'description', 'remarks']\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Extract the first part of the filename (before any year or bracketed sections)\n",
    "def extract_pdf_id(pdf_path):\n",
    "    # Extract the base filename without the extension\n",
    "    base_filename = os.path.basename(pdf_path).split('.')[0]\n",
    "    \n",
    "    # Match the first part before any year or parentheses, i.e., extract 'AEROX 155' or 'FJR1300A'\n",
    "    match = re.match(r\"([A-Za-z0-9 ]+)\", base_filename)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1).strip()  # Return the matched pdf_id, cleaned of extra spaces\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Extract year from the filename (if available)\n",
    "def extract_year(pdf_path):\n",
    "    year_match = re.search(r\"'(\\d{2})\", pdf_path)\n",
    "    if year_match:\n",
    "        return f\"20{year_match.group(1)}\"  # Convert '15' to '2015'\n",
    "    else:\n",
    "        return None  # If no year is found, set it to None\n",
    "\n",
    "# Main function to process PDF\n",
    "def main(pdf_path):\n",
    "    # Extract pdf_id and year\n",
    "    pdf_id = extract_pdf_id(pdf_path)\n",
    "    year = extract_year(pdf_path)\n",
    "\n",
    "    # Extract all text from the PDF\n",
    "    all_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    # Process the extracted text to generate structured data\n",
    "    df = process_data(all_text, pdf_id, year)\n",
    "\n",
    "    # Display the structured table\n",
    "    print(df.to_string(index=False))\n",
    "\n",
    "    # Adding data to Database\n",
    "    df.to_sql(\"master_parts_list\", engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "\n",
    "# Run the main function\n",
    "main(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc421333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview extracted raw text\n",
    "import pdfplumber\n",
    "\n",
    "# Initialize a variable to hold all extracted text\n",
    "all_text = \"\"\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    # Loop through the specified page range\n",
    "    for page_num in range(start_page - 1, end_page):  # page_num is 0-indexed, so subtract 1 from start_page\n",
    "        page = pdf.pages[page_num]\n",
    "        text = page.extract_text()  # Extract text from the page\n",
    "        \n",
    "        if text:  # If the page contains text\n",
    "            all_text += f\"\\n--- Page {page_num + 1} ---\\n{text}\\n\"  # page_num + 1 to keep it 1-indexed in output\n",
    "\n",
    "# Optionally, print the extracted text or save to a file\n",
    "print(all_text)\n",
    "\n",
    "# If you want to save the text to a text file:\n",
    "with open(\"extracted_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c72e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prev VER: Before combining image + data extraction\n",
    "\n",
    "# Function to extract text from the PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    all_text = \"\"\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text() or \"\"\n",
    "            lines = text.split('\\n')\n",
    "            first_line = lines[0].strip() if lines else \"\"\n",
    "\n",
    "            # Skip pages without \"FIG.\"\n",
    "            if not any(\"FIG.\" in line for line in lines):\n",
    "                continue\n",
    "\n",
    "            # Stop if \"NUMERICAL INDEX\" is found\n",
    "            if \"NUMERICAL INDEX\" in first_line:\n",
    "                print(f\"Found 'NUMERICAL INDEX' on page {page_num + 1}. Stopping further processing.\")\n",
    "                break\n",
    "\n",
    "            # Begin assembling text for the current page\n",
    "            page_text = f\"\\n--- Page {page_num + 1} ---\\n{text}\\n\"\n",
    "\n",
    "            # Check for images\n",
    "            if page.images:\n",
    "                page_text += f\"\\n[Images Found: {len(page.images)}]\\n\"\n",
    "                for idx, img in enumerate(page.images, start=1):\n",
    "                    img_info = (\n",
    "                        f\"  Image {idx}: x0={img['x0']}, y0={img['y0']}, \"\n",
    "                        f\"x1={img['x1']}, y1={img['y1']}, width={img['width']}, \"\n",
    "                        f\"height={img['height']}, name={img.get('name', 'N/A')}\"\n",
    "                    )\n",
    "                    page_text += img_info + \"\\n\"\n",
    "            else:\n",
    "                page_text += \"[No images found on this page.]\\n\"\n",
    "\n",
    "            all_text += page_text\n",
    "\n",
    "    return all_text\n",
    "\n",
    "# Process function now accepts a pdf_id as argument\n",
    "def process_data(text, pdf_id, year, num_model=3):\n",
    "    rows = []\n",
    "    lines = text.strip().split('\\n')\n",
    "\n",
    "    # Initialize columns for data collection\n",
    "    fig_no = \"\"\n",
    "    c_name = \"\"\n",
    "    prev_fig_no = \"\"\n",
    "    prev_c_name = \"\"\n",
    "    prev_ref_no = \"\"\n",
    "    collect_data = False\n",
    "\n",
    "    for line_num, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Detect if page is a Parts Information pages then stores Fig Num and Component Name\n",
    "        if line.startswith('FIG.'):\n",
    "            tokens = line.split()\n",
    "            if len(tokens) >= 3:\n",
    "                fig_no = tokens[1]\n",
    "                c_name = \" \".join(tokens[2:])\n",
    "                prev_fig_no = fig_no\n",
    "                prev_c_name = c_name\n",
    "                collect_data = True\n",
    "            continue\n",
    "\n",
    "        # Safety Net 1: Skip lines until valid data table starts\n",
    "        if not collect_data:\n",
    "            continue\n",
    "\n",
    "        # Safety Net 2: Use previous figure number and component name if not explicitly found in the current line\n",
    "        if not fig_no:\n",
    "            fig_no = prev_fig_no\n",
    "            c_name = prev_c_name\n",
    "\n",
    "        parts = line.split()\n",
    "    \n",
    "        # Allow data to be collected even if ref_no is missing\n",
    "        is_valid_data_line = (\n",
    "            len(parts) >= 2 and  # Check if the line has at least part number and description\n",
    "            (re.match(r'\\w+[-–]\\w+', parts[0]) or re.match(r'\\d+', parts[0]))  # Check if first part is a valid part number or ref number\n",
    "        )\n",
    "\n",
    "        if not is_valid_data_line:\n",
    "            continue\n",
    "\n",
    "        # Determine ref_no and part_no\n",
    "        if parts[0].isdigit():\n",
    "            ref_no = parts[0]\n",
    "            part_no = parts[1]\n",
    "            rest = parts[2:] # Description + Quantity + Remarks\n",
    "            prev_ref_no = ref_no\n",
    "        else:\n",
    "            ref_no = prev_ref_no\n",
    "            part_no = parts[0]\n",
    "            rest = parts[1:] # Description + Quantity + Remarks\n",
    "\n",
    "        rest = \" \".join(rest).split()\n",
    "\n",
    "        description = \"\"\n",
    "        remarks = \"\"\n",
    "        numbers = []\n",
    "        found_numbers = False\n",
    "\n",
    "        for item in rest:\n",
    "            if item.isdigit():\n",
    "                numbers.append(item)\n",
    "                found_numbers = True\n",
    "                continue\n",
    "            if not found_numbers:\n",
    "                description += item + \" \"\n",
    "            else:\n",
    "                remarks += item + \" \"\n",
    "        \n",
    "        if len(numbers) > num_model:\n",
    "            description += numbers[0]\n",
    "        \n",
    "        description = description.strip()\n",
    "        remarks = remarks.strip()\n",
    "\n",
    "        # Append pdf_id and year along with the rest of the data\n",
    "        rows.append([pdf_id, year, \"Yamaha\", fig_no, c_name, ref_no, part_no, description, remarks])\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        rows,\n",
    "        columns=['pdf_id', 'year', 'brand', 'fig_no', 'component_name', 'ref_no', 'part_no', 'description', 'remarks']\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Extract the first part of the filename (before any year or bracketed sections)\n",
    "def extract_pdf_id(pdf_path):\n",
    "    # Extract the base filename without the extension\n",
    "    base_filename = os.path.basename(pdf_path).split('.')[0]\n",
    "    \n",
    "    # Match the first part before any year or parentheses, i.e., extract 'AEROX 155' or 'FJR1300A'\n",
    "    match = re.match(r\"([A-Za-z0-9 ]+)\", base_filename)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1).strip()  # Return the matched pdf_id, cleaned of extra spaces\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Extract year from the filename (if available)\n",
    "def extract_year(pdf_path):\n",
    "    year_match = re.search(r\"'(\\d{2})\", pdf_path)\n",
    "    if year_match:\n",
    "        return f\"20{year_match.group(1)}\"  # Convert '15' to '2015'\n",
    "    else:\n",
    "        return None  # If no year is found, set it to None\n",
    "\n",
    "# Main function to process PDF\n",
    "def main(pdf_path):\n",
    "    # Extract pdf_id and year\n",
    "    pdf_id = extract_pdf_id(pdf_path)\n",
    "    year = extract_year(pdf_path)\n",
    "\n",
    "    # Create a session\n",
    "    with Session(engine) as session:\n",
    "        # Check if the pdf_id already exists in the table\n",
    "        existing = session.execute(\n",
    "            select(1).select_from(master_parts_list).where(master_parts_list.c.pdf_id == pdf_id)\n",
    "        ).first()\n",
    "\n",
    "        if existing:\n",
    "            print(f\"pdf_id '{pdf_id}' already exists in the database. Skipping insert.\")\n",
    "            return\n",
    "\n",
    "    # Extract all text from the PDF\n",
    "    all_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    # Process the extracted text to generate structured data\n",
    "    df = process_data(all_text, pdf_id, year)\n",
    "\n",
    "    # Display the structured table\n",
    "    print(df.to_string(index=False))\n",
    "\n",
    "    # Add data to Database\n",
    "    #df.to_sql(\"master_parts_list\", engine, if_exists=\"append\", index=False, method=\"multi\") # Doesnt work rn cuz of image_id\n",
    "\n",
    "# Run the main function\n",
    "main(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d20a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] All FIG images for 'AEROX 155' already exist.\n",
      "[INFO] Inserted parts data for 'AEROX 155'.\n"
     ]
    }
   ],
   "source": [
    "# Final VER: image_id = pdf_id + \"_\" + fig_no\n",
    "# ---------- HELPERS ----------\n",
    "def extract_pdf_id(pdf_path):\n",
    "    base_filename = os.path.basename(pdf_path).split('.')[0]\n",
    "    match = re.match(r\"([A-Za-z0-9 ]+)\", base_filename)\n",
    "    if match:\n",
    "        return match.group(1).replace(\" \", \"\")  # Remove all spaces\n",
    "    return None\n",
    "\n",
    "def extract_year(pdf_path):\n",
    "    year_match = re.search(r\"'(\\d{2})\", pdf_path)\n",
    "    return f\"20{year_match.group(1)}\" if year_match else None\n",
    "\n",
    "# ---------- IMAGE EXTRACTION ----------\n",
    "def extract_images_with_fig_labels(pdf_path, pdf_id, engine):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    data = []\n",
    "\n",
    "    # Step 1: Get existing (pdf_id, fig_no) combos from DB\n",
    "    existing_figs = get_existing_fig_combos(engine, pdf_id)\n",
    "\n",
    "    seen_figs = set()  # Track unique figs within the PDF\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "\n",
    "        matches = re.findall(r\"FIG\\.\\s*([\\w-]+)\", text)\n",
    "        if not matches:\n",
    "            continue\n",
    "\n",
    "        fig_no = matches[0]\n",
    "\n",
    "        if fig_no in seen_figs or fig_no in existing_figs:\n",
    "            continue  # Skip if already handled or exists in DB\n",
    "\n",
    "        image_list = page.get_images(full=True)\n",
    "        if not image_list:\n",
    "            continue\n",
    "\n",
    "        xref = image_list[0][0]\n",
    "        base_image = doc.extract_image(xref)\n",
    "        image = base_image[\"image\"]\n",
    "\n",
    "        image_id = \"_\".join([pdf_id, fig_no])\n",
    "\n",
    "        data.append({\n",
    "            \"image_id\" : image_id,\n",
    "            \"pdf_id\": pdf_id,\n",
    "            \"fig_no\": fig_no,\n",
    "            \"image\": image\n",
    "        })\n",
    "        seen_figs.add(fig_no)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def get_existing_fig_combos(engine, pdf_id):\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(\n",
    "            text(\"SELECT fig_no FROM parts_images WHERE pdf_id = :pdf_id\"),\n",
    "            {\"pdf_id\": pdf_id}\n",
    "        )\n",
    "        return set(str(row[0]) for row in result.fetchall())  # Cast to str for consistent comparison\n",
    "\n",
    "# ---------- TEXT EXTRACTION ----------\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    all_text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text() or \"\"\n",
    "            lines = text.split('\\n')\n",
    "            first_line = lines[0].strip() if lines else \"\"\n",
    "            if not any(\"FIG.\" in line for line in lines):\n",
    "                continue\n",
    "            if \"NUMERICAL INDEX\" in first_line:\n",
    "                break\n",
    "            all_text += f\"\\n--- Page {page_num + 1} ---\\n{text}\\n\"\n",
    "    return all_text\n",
    "\n",
    "def yamaha_process_data(text, pdf_id, year, num_model):\n",
    "    rows = []\n",
    "    lines = text.strip().split('\\n')\n",
    "    fig_no = c_name = prev_fig_no = prev_c_name = prev_ref_no = \"\"\n",
    "    collect_data = False\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line: continue\n",
    "        if line.startswith('FIG.'):\n",
    "            tokens = line.split()\n",
    "            if len(tokens) >= 3:\n",
    "                fig_no = tokens[1]\n",
    "                c_name = \" \".join(tokens[2:])\n",
    "                prev_fig_no, prev_c_name = fig_no, c_name\n",
    "                collect_data = True\n",
    "            continue\n",
    "        if not collect_data: continue\n",
    "        if not fig_no:\n",
    "            fig_no, c_name = prev_fig_no, prev_c_name\n",
    "\n",
    "        parts = line.split()\n",
    "        is_valid_data_line = (\n",
    "            len(parts) >= 2 and \n",
    "            (re.match(r'\\w+[-–]\\w+', parts[0]) or parts[0].isdigit())\n",
    "        )\n",
    "        if not is_valid_data_line:\n",
    "            continue\n",
    "\n",
    "        if parts[0].isdigit():\n",
    "            ref_no = parts[0]\n",
    "            part_no = parts[1]\n",
    "            rest = parts[2:]\n",
    "            prev_ref_no = ref_no\n",
    "        else:\n",
    "            ref_no = prev_ref_no\n",
    "            part_no = parts[0]\n",
    "            rest = parts[1:]\n",
    "\n",
    "        rest = \" \".join(rest).split()\n",
    "        description = remarks = \"\"\n",
    "        numbers = []\n",
    "        found_numbers = False\n",
    "        for item in rest:\n",
    "            if item.isdigit():\n",
    "                numbers.append(item)\n",
    "                found_numbers = True\n",
    "                continue\n",
    "            if not found_numbers:\n",
    "                description += item + \" \"\n",
    "            else:\n",
    "                remarks += item + \" \"\n",
    "        if len(numbers) > num_model:\n",
    "            description += numbers[0]\n",
    "\n",
    "        image_id = \"_\".join([pdf_id, fig_no])\n",
    "\n",
    "        rows.append([pdf_id, year, \"Yamaha\", fig_no, c_name, ref_no, part_no, description.strip(), remarks.strip(), image_id])\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\n",
    "        'pdf_id', 'year', 'brand', 'fig_no', 'component_name',\n",
    "        'ref_no', 'part_no', 'description', 'remarks', 'image_id'\n",
    "    ])\n",
    "\n",
    "# ---------- MAIN PROCESS ----------\n",
    "def yamaha_data_extraction(pdf_path):\n",
    "\n",
    "    pdf_id = extract_pdf_id(pdf_path)\n",
    "    year = extract_year(pdf_path)\n",
    "\n",
    "    with Session(engine) as session:\n",
    "        df_images = extract_images_with_fig_labels(pdf_path, pdf_id, engine)\n",
    "        image_message = f\"[INFO] Inserted {len(df_images)} new images for '{pdf_id}'.\"\n",
    "        if not df_images.empty:\n",
    "            df_images.to_sql(\"parts_images\", engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "            print(image_message)\n",
    "        else:\n",
    "            print(image_message + f\" All images for '{pdf_id}' already exist.\")\n",
    "\n",
    "        # Step 2: Check if parts data already exists\n",
    "        existing = session.execute(\n",
    "            select(1).select_from(master_parts_list).where(master_parts_list.c.pdf_id == pdf_id)\n",
    "        ).first()\n",
    "\n",
    "        if existing:\n",
    "            print(f\"[INFO] Master Parts data for '{pdf_id}' already exists.\")\n",
    "            return\n",
    "            \n",
    "    # Step 3: Extract and process parts data (outside session scope)\n",
    "    all_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    df_parts = yamaha_process_data(all_text, pdf_id, year, num_model=3)\n",
    "\n",
    "    if not df_parts.empty:\n",
    "        df_parts.to_sql(\"master_parts_list\", engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "        print(f\"[INFO] Inserted parts data for '{pdf_id}'.\")\n",
    "    else:\n",
    "        print(f\"[INFO] Error, no parts data extracted for '{pdf_id}'.\")\n",
    "\n",
    "brand = \"Yamaha\"\n",
    "supported_brands = ['Yamaha', 'Honda']\n",
    "\n",
    "if brand in supported_brands:\n",
    "    if brand == \"Yamaha\":\n",
    "        yamaha_data_extraction(pdf_path)\n",
    "    elif brand == \"Honda\":\n",
    "        print(\"Nigger\")\n",
    "else:\n",
    "    print (f\"Brand not supported, Available Brands: {supported_brands}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a2b6ef",
   "metadata": {},
   "source": [
    "### Week 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6796366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
