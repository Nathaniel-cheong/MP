{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b2c0071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Ref.                                                                                                   \n",
      "             No. Part No.      Description   CRF1000 CRF1000A CRF1000D Serial No. Parts catalogue code              \n",
      "                                             G H  G  H G H                                                          \n",
      "              1 11210-MJP-G50 PAN COMP., OIL •••••••••••••• 1 - 1 - - - -------- --------2ED,2GS,2RU,2U,3ED,3GS,3RU,3TH,3U,ED,GS,RU,TH,U\n",
      "               11210-MJP-G51 •••••••••••••••••••••••••••• - 1 1 - - - -------- --------2CH,4CH,U                    \n",
      "                                             - -  - 1  - -                                                          \n",
      "               11210-MJP-G81 •••••••••••••••••••••••••••• - - - - 1 - -------- --------2CH,2KO,3KO,4CH              \n",
      "               11210-MJP-G80 •••••••••••••••••••••••••••• - - - - 1 - -------- --------2ED,2GS,2RU,2U,3ED,3GS,3RU,3U,ED,GS,RU,TH\n",
      "               11210-MJP-G81 •••••••••••••••••••••••••••• - - - - - 1                                               \n",
      "              2 11395-MJP-G51 GASKET, OIL PAN ••••••••••••• 1 1 1 1 1 1                                             \n",
      "              3 15010-MCE-H51 FILTER SET, OIL ••••••••••••• (1) (1) (1) (1) (1) (1)                                 \n",
      "              4 15100-MJP-G50 PUMP ASSY., OIL ••••••••••••• 1 - 1 - - - -------- 50053162ED,2RU,2U,3ED,3RU,3TH,3U,ED,RU,TH,U\n",
      "               15100-MJP-G51 •••••••••••••••••••••••••••• 1 - 1 - - - 5005317 --------2ED,2RU,2U,3ED,3RU,3TH,3U,ED,RU,TH,U\n",
      "                                             - 1  1 -  - - -------- --------2CH,2GS,3GS,4CH,GS,U                    \n",
      "                                             - -  - 1  - -                                                          \n",
      "              5 15100-MJP-G81 PUMP ASSY., OIL ••••••••••••• - - - - 1 1                                             \n",
      "              6 15104-MGS-D20 PIPE, OIL PASS •••••••••••••• - - - - 2 2                                             \n",
      "              7 15130-MJP-G50 GEAR COMP., OIL PUMP DRIVEN                                                          \n",
      "                                        (21T) 1 1 1 1  1 1                                                          \n",
      "              8 15136-MJP-G50 PLATE, OIL PUMP DRIVEN GEAR                                                          \n",
      "                                        SHAFT 1 1 1 1  1 1                                                          \n",
      "              9 15150-MJP-G50 STRAINER COMP., OIL ••••••••• 1 1 1 1 1 1                                             \n",
      "             10 15154-MAT-000 PACKING, OIL STRAINER ••••••• 1 1 1 1 1 1                                             \n",
      "             11 15410-MFJ-D01 CARTRIDGE, OIL FILTER                                                                \n",
      "                                     (TOYO ROKI) 1 1 1 1 1 1                                                        \n",
      "             12 15421-MJP-G50 SCREEN, OIL FILTER •••••••••• 1 1 1 1 1 1                                             \n",
      "             13 90006-GHB-680 BOLT, FLANGE, 6X28(NSHF) •••• 14 14 14 14 14 14                                       \n",
      "             14 90019-MB0-000 BOSS, OIL FILTER •••••••••••• 1 1 1 1 1 1                                             \n",
      "             15 90022-MJP-G50 BOLT, SPECIAL, 6X32 ••••••••• 3 3 3 3 3 3                                             \n",
      "         162                                                                                                        \n",
      "                                                    2016.09.20 E                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "             E-12                               OIL  PAN/OIL  PUMP                                                  \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                          2         \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                Reqd. QTY                                                           \n",
      "             Ref.                                                                                                   \n",
      "             No. Part No.      Description   CRF1000 CRF1000A CRF1000D Serial No. Parts catalogue code              \n",
      "                                             G H  G  H G H                                                          \n",
      "             16 90103-MEN-710 BOLT, SPECIAL, 6MM •••••••••• 1 1 1 1 1 1                                             \n",
      "             17 90131-883-000 BOLT, DRAIN PLUG, 12X15 ••••• 2 2 2 2 2 2                                             \n",
      "             18 90406-MJP-G50 WASHER, 12X21X1.0 ••••••••••• 1 1 1 1 1 1                                             \n",
      "             19 91303-KF0-003 O-RING, 14.8X2.4(ARAI) •••••• 2 2 2 2 2 2                                             \n",
      "             20 91311-RFH-003 O-RING, 7.7X1.9 ••••••••••••• - - - - 4 4                                             \n",
      "             21 91315-MGS-D20 RING, BACK UP, 8X11 ••••••••• - - - - 4 4                                             \n",
      "             22 91352-MGE-003 O-RING, 21.5X2.9 •••••••••••• 1 1 1 1 1 1                                             \n",
      "             23 94109-12000 WASHER, DRAIN PLUG, 12MM •••• 2 2 2 2 2 2                                               \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                                    \n",
      "                                                                                                        163         \n",
      "                                                    2016.09.20 E\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pdfplumber\n",
    "\n",
    "def extract_section_with_layout(pdf_path: str, section_code: str, section_title: str) -> str:\n",
    "    \"\"\"\n",
    "    Finds the specified section by plain-text scan (no layout=True),\n",
    "    locates the 'Reqd. QTY' start of the main table, then finds the\n",
    "    next section header to mark the end. Finally re-extracts that\n",
    "    range in layout mode to preserve spacing.\n",
    "    \"\"\"\n",
    "    code = section_code.upper()\n",
    "    title = section_title.upper()\n",
    "\n",
    "    # Patterns\n",
    "    next_sec_re     = re.compile(r'^[A-Z]+-\\d+', re.IGNORECASE)\n",
    "    table_header_re = re.compile(r'\\bReqd\\.?\\s*QTY\\b', re.IGNORECASE)\n",
    "\n",
    "    # Phase 1: plain-text scan to find start_page, header_hit, end_page\n",
    "    start_page = None\n",
    "    header_hit = False\n",
    "    end_page   = None\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text() or \"\"\n",
    "            for ln in text.splitlines():\n",
    "                up = ln.strip().upper()\n",
    "                if start_page is None:\n",
    "                    # Detect section header (FRAMEGROUP or simple)\n",
    "                    if (\"FRAMEGROUP\" in up and up.startswith(code) and title in up) or \\\n",
    "                       (up.startswith(code) and title in up):\n",
    "                        start_page = i\n",
    "                        break\n",
    "                elif not header_hit:\n",
    "                    # Detect the table header\n",
    "                    if table_header_re.search(up):\n",
    "                        header_hit = True\n",
    "                    # continue scanning same page to look for end only after header\n",
    "                else:\n",
    "                    # after header, detect next section\n",
    "                    if next_sec_re.match(up) and not up.startswith(code):\n",
    "                        end_page = i\n",
    "                        break\n",
    "            if end_page is not None:\n",
    "                break\n",
    "\n",
    "        # Validation\n",
    "        if start_page is None or not header_hit:\n",
    "            return f\"Section '{section_code} {section_title}' not found or missing table header.\"\n",
    "\n",
    "        if end_page is None:\n",
    "            end_page = len(pdf.pages)\n",
    "\n",
    "        # Phase 2: layout-mode extraction on full range [start_page..end_page)\n",
    "        collected = []\n",
    "        in_table  = False\n",
    "\n",
    "        for pi in range(start_page, end_page):\n",
    "            layout = pdf.pages[pi].extract_text(layout=True) or \"\"\n",
    "            for ln in layout.splitlines():\n",
    "                up = ln.strip().upper()\n",
    "                if not in_table:\n",
    "                    if table_header_re.search(up):\n",
    "                        in_table = True\n",
    "                    continue\n",
    "                # Stop at next section if it sneaks in layout text\n",
    "                if next_sec_re.match(up) and not up.startswith(code):\n",
    "                    break\n",
    "                collected.append(ln)\n",
    "\n",
    "        return \"\\n\".join(collected).rstrip()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file = \"CRF1000 A_PC_13MJPG02_(G.H).pdf\"\n",
    "    print(extract_section_with_layout(\n",
    "        pdf_file,\n",
    "        section_code=\"E-12\",\n",
    "        section_title=\"OIL PAN/OIL PUMP\",\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67639b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '22100-MJP-G50', 'OUTER COMP., CLUTCH', '']\n",
      "['2', '22116-MJP-G50', 'GUIDE, CLUTCH OUTER', '']\n",
      "['3', '22121-MJP-G51', 'CENTER, CLUTCH', '']\n",
      "['4', '22125-HP6-A00', 'SEAT, JUDDER SPRING', '']\n",
      "['5', '22210-MJP-305', 'DISK SET, CLUTCH', '']\n",
      "['6', '22325-MJP-G51', 'SPRING, JUDDER', '']\n",
      "['7', '22350-MJP-G51', 'PLATE COMP., CLUTCH PRESSURE', '']\n",
      "['8', '22361-MJP-G51', 'PLATE, SETTING', '']\n",
      "['9', '22401-MJP-G51', 'SPRING, CLUTCH', '']\n",
      "['10', '22425-MJP-G51', 'SEAT, CLUTCH SPRING', '']\n",
      "['11', '22847-MJP-G50', 'PIN, CLUTCH LIFTER', '']\n",
      "['12', '23103-MJP-G50', 'GEAR, PRIMARY DRIVE(45T)', '']\n",
      "['13', '23104-MJP-G50', 'SUB GEAR, PRIMARY(45T)', '']\n",
      "['14', '23115-MW4-000', 'SPRING, PRIMARY DAMPER', '']\n",
      "['15', '90013-MJP-G50', 'BOLT, SPECIAL, 10X25', '']\n",
      "['16', '90050-MJP-G51', 'BOLT, FLANGE, 6X35', '']\n",
      "['17', '90231-MS2-610', 'NUT, LOCK, 25MM', '']\n",
      "['18', '90401-MEA-670', 'WASHER, 35X50X3.2', '']\n",
      "['19', '90401-MS2-610', 'WASHER, THRUST, 28.2X56X2', '']\n",
      "['20', '90414-MGE-D00', 'WASHER, 10.5X36X4', '']\n",
      "['21', '90432-MM8-003', 'WASHER, SPRING, 25MM (CHUO SPRING)', '']\n",
      "['22', '90451-VM0-000', 'WASHER, THRUST, 25X40X2', '']\n",
      "['23', '91026-MV9-671', 'BEARING, NEEDLE, 35X42X23 1 1 1 1 - - 2016.09.20 E E-7-1 CLUTCH(CRF1000D) Ref. (Relative ref. Number) L.O.N. F.R.T. No. Description 1 211100 GEAR, PRIMARY DRIVEN 2.0 2 (16) 2121P5 CLUTCH ASSEMBLY 2.0 .NOTE: Same time for two units 3 (4,5,15,17,18) 1101H9 PIPE, OIL FEED 0.1 .NOTE: Same time for two units 6 (7,8) 2111F8 GEAR, PRIMARY DRIVE(A) 1.9 9 (10) 2121N3 GUIDE, CLUTCH 1.9 .NOTE: Same time for two units Reqd. QTY Ref. No. Part No. Description CRF1000 CRF1000A CRF1000D Serial No. Parts catalogue code', '']\n",
      "['1', '22100-HL4-003', 'GEAR COMP., PRIMARY DRIVEN (81T)', '']\n",
      "['2', '22500-MJP-G81', 'CLUTCH ASSY.', '']\n",
      "['3', '22711-MJP-G80', 'PIPE COMP. A, FEED', '']\n",
      "['4', '22712-MJP-G80', 'PIPE COMP. B, FEED', '']\n",
      "['5', '22720-MJP-G80', 'GUIDE COMP., FEED PIPE', '']\n",
      "['6', '23103-MJP-G80', 'GEAR, PRIMARY DRIVE(43T)', '']\n",
      "['7', '23104-HL4-000', 'SUB GEAR, PRIMARY(43T)', '']\n",
      "['8', '23115-MW4-000', 'SPRING, PRIMARY DAMPER', '']\n",
      "['9', '23405-HL4-000', 'GUIDE, FIRST CLUTCH GEAR(30T)', '']\n",
      "['10', '23406-HL4-000', 'GUIDE, SECOND CLUTCH GEAR(30T)', '']\n",
      "['11', '90089-KAS-900', 'BOLT, FLANGE SOCKET, 5X14', '']\n",
      "['12', '90201-HL4-000', 'NUT, LOCK, 22MM', '']\n",
      "['13', '90403-HL4-000', 'WASHER, 29.5X50X2', '']\n",
      "['14', '90404-HL4-000', 'WASHER, 22X37X5', '']\n",
      "['15', '91302-PA9-003', 'O-RING, 39.8X2.2(ARAI)', '']\n",
      "['16', '91302-RGC-003', 'O-RING, 35X2.2', '']\n",
      "['17', '91308-PY4-003', 'O-RING, 10.7X1.9', '']\n",
      "['18', '91315-PC9-004', 'O-RING, 6X1.5(N0K)', '']\n",
      "['19', '94302-05080', 'PIN B, DOWEL, 5X8', '']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pdfplumber\n",
    "\n",
    "def extract_section_with_layout(pdf_path: str, section_code: str, section_title: str):\n",
    "    \"\"\"\n",
    "    Finds a specified section, locates 'Reqd. QTY', extracts in layout mode,\n",
    "    then parses each part and variant into [REF_NO, PART_NO, DESCRIPTION, CATALOGUE_CODE].\n",
    "    Stops collecting once it encounters any line containing 'PART', 'NO', and 'INDEX'.\n",
    "    \"\"\"\n",
    "    code = section_code.upper()\n",
    "    title = section_title.upper()\n",
    "\n",
    "    next_sec_re     = re.compile(r'^[A-Z]+-\\d+', re.IGNORECASE)\n",
    "    table_header_re = re.compile(r'\\bReqd\\.?\\s*QTY\\b', re.IGNORECASE)\n",
    "    part_no_re      = re.compile(r'\\b[0-9]{5,}(?:-[A-Z0-9-]+)+\\b')\n",
    "    end_re          = re.compile(r'.*PART\\s*NO\\.?\\s*INDEX.*', re.IGNORECASE)\n",
    "\n",
    "    # Phase 1: locate page range\n",
    "    start_page = header_hit = None\n",
    "    end_page = None\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            for ln in (page.extract_text() or \"\").splitlines():\n",
    "                u = ln.strip().upper()\n",
    "                if start_page is None:\n",
    "                    if ((\"FRAMEGROUP\" in u and u.startswith(code) and title in u)\n",
    "                        or (u.startswith(code) and title in u)):\n",
    "                        start_page = i\n",
    "                        break\n",
    "                elif not header_hit:\n",
    "                    if table_header_re.search(u):\n",
    "                        header_hit = True\n",
    "                else:\n",
    "                    if next_sec_re.match(u) and not u.startswith(code):\n",
    "                        end_page = i\n",
    "                        break\n",
    "            if end_page is not None:\n",
    "                break\n",
    "        if start_page is None or not header_hit:\n",
    "            raise ValueError(f\"Section '{section_code} {section_title}' not found or missing table header.\")\n",
    "        if end_page is None:\n",
    "            end_page = len(pdf.pages)\n",
    "\n",
    "        # Phase 2: collect layout-preserved lines\n",
    "        collected = []\n",
    "        in_table = False\n",
    "        stop_all = False\n",
    "        for pi in range(start_page, end_page):\n",
    "            for ln in (pdf.pages[pi].extract_text(layout=True) or \"\").splitlines():\n",
    "                u = ln.strip().upper()\n",
    "                # if we see \"PART ... NO ... INDEX\" in any spacing, stop entirely\n",
    "                if end_re.match(u):\n",
    "                    stop_all = True\n",
    "                    break\n",
    "                if not in_table:\n",
    "                    if table_header_re.search(u):\n",
    "                        in_table = True\n",
    "                    continue\n",
    "                if next_sec_re.match(u) and not u.startswith(code):\n",
    "                    break\n",
    "                collected.append(ln)\n",
    "            if stop_all:\n",
    "                break\n",
    "\n",
    "    # Phase 3: group into per-part buffers\n",
    "    records = []\n",
    "    last_ref = \"\"\n",
    "    for ln in collected:\n",
    "        m_pno = part_no_re.search(ln)\n",
    "        if m_pno:\n",
    "            m_ref = re.match(r'^\\s*(?:\\((\\d+)\\)|(\\d+))\\s+', ln)\n",
    "            if m_ref:\n",
    "                last_ref = m_ref.group(1) or m_ref.group(2)\n",
    "            ref = last_ref\n",
    "            pno = m_pno.group(0)\n",
    "            buf = [ln[m_pno.end():].strip()]\n",
    "            records.append({\"ref\": ref, \"part_no\": pno, \"buf\": buf})\n",
    "        else:\n",
    "            if not records:\n",
    "                continue\n",
    "            txt = ln.strip()\n",
    "            if re.fullmatch(r'\\d+', txt) or re.fullmatch(r'\\d{4}\\.\\d{2}\\.\\d{2}', txt):\n",
    "                continue\n",
    "            records[-1][\"buf\"].append(txt)\n",
    "\n",
    "    # Phase 4: parse each buffer\n",
    "    out = []\n",
    "    for rec in records:\n",
    "        raw = \" \".join(rec[\"buf\"])\n",
    "        raw = raw.replace('∙','').replace('•','').replace('\\uf020','')\n",
    "        raw = re.sub(r'\\s+', ' ', raw).strip()\n",
    "\n",
    "        idx = raw.find(\"--------\")\n",
    "        desc_part = raw[:idx].strip() if idx != -1 else raw\n",
    "        cat_part  = raw[idx+8:].strip() if idx != -1 else \"\"\n",
    "\n",
    "        desc_part = re.sub(r'\\.{2,}\\s+\\d.*$', '', desc_part).strip()\n",
    "        desc_part = re.sub(r'\\s+GK[A-Za-z0-9]+\\s*$', '', desc_part)\n",
    "        desc_part = re.sub(r'\\s+(?:-+|\\d+)+\\s*$', '', desc_part)\n",
    "        desc = re.sub(r'\\s+\\d+\\s+\\d{4}\\.\\d{2}\\.\\d{2}.*$', \"\", desc_part).strip()\n",
    "        desc = re.sub(r'(?:\\s+(?:\\(\\d+\\)|-+|\\d+))+$', \"\", desc).strip()\n",
    "        desc = re.sub(r'\\.{2,}$', \"\", desc).strip()\n",
    "        desc = re.sub(r'(?:\\s+[A-Z])+$', '', desc).strip()\n",
    "        desc = \"\" if not re.search(r'[A-Za-z]', desc) else desc\n",
    "\n",
    "        if cat_part.upper().startswith(\"GK\") and len(cat_part) > 8:\n",
    "            cat_clean = cat_part[8:].split()[0]\n",
    "        else:\n",
    "            m_codes = re.match(r'[-\\s]*([0-9A-Z,\\s]+)', cat_part)\n",
    "            raw_codes = m_codes.group(1) if m_codes else \"\"\n",
    "            cat_clean = raw_codes.replace(\" \", \"\")\n",
    "            cat_clean = re.sub(r'([A-Z])(?=\\d)', r'\\1,', cat_clean)\n",
    "            cat_clean = re.sub(\n",
    "                r'(?<=[0-9A-Z]{2})(?=[A-Z]{2}(?:,|$))',\n",
    "                ',',\n",
    "                cat_clean\n",
    "            )\n",
    "\n",
    "        cat_clean = re.sub(r'\\d{4}$', '', cat_clean)\n",
    "        tokens = [t for t in cat_clean.split(',') if t]\n",
    "        seen = set()\n",
    "        final_codes = [c for c in tokens if c not in seen and not seen.add(c)]\n",
    "        cat = \",\".join(final_codes)\n",
    "\n",
    "        m3 = re.match(r'^(.+?)([A-Z]{3,})$', rec[\"part_no\"])\n",
    "        if m3:\n",
    "            core, suf = m3.group(1), m3.group(2)\n",
    "            pno = core + suf[:2]\n",
    "            desc = f\"{suf[2:]} {desc}\".strip()\n",
    "        else:\n",
    "            pno = rec[\"part_no\"]\n",
    "\n",
    "        out.append([rec[\"ref\"], pno, desc, cat])\n",
    "\n",
    "    return out\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file = \"CRF1000 A_PC_13MJPG02_(G.H).pdf\"\n",
    "    for row in extract_section_with_layout(pdf_file, \"E-7\", \"CLUTCH(CRF1000/CRF1000A)\"):\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f483c48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ref_no         part_no                 description remarks\n",
      "0       1   11330-MJP-G50   COVER COMP., R. CRANKCASE        \n",
      "1       2   11376-MJP-G50        COVER, R. RR. ENGINE        \n",
      "2       3   11385-MJF-A00                      COLLAR        \n",
      "3       4   11394-MJP-G51  GASKET, R. CRANKCASE COVER        \n",
      "4       5   19200-MJP-G50           PUMP COMP., WATER        \n",
      "5       6   19226-MJP-G50     GASKET, WATER PUMP BODY        \n",
      "6       7   22810-MJP-G50         LEVER COMP., CLUTCH        \n",
      "7       8   22815-413-000        SPRING, CLUTCH LEVER        \n",
      "8       9   22821-MJP-G50      RECEIVER, CLUTCH CABLE        \n",
      "9      10   90004-MJP-G50   BOLT, FLANGE SOCKET, 6X28        \n",
      "10     11   90085-MGC-920         BOLT, SPECIAL, 6X17        \n",
      "11     12   90488-425-000        WASHER, SEALING, 6MM        \n",
      "12     13   91053-MFJ-D01   BEARING, NEEDLE, 12X16X10        \n",
      "13     14   91205-KF0-003     OIL SEAL, 12X20X5(ARAI)        \n",
      "14     15   91315-MJP-G51            SEAL, WATER PIPE        \n",
      "15     16     94301-06100             DOWEL PIN, 6X10        \n",
      "16     17     94301-08140             DOWEL PIN, 8X14        \n",
      "17     18  95701-06016-00          BOLT, FLANGE, 6X16        \n",
      "18     19  95701-06025-00          BOLT, FLANGE, 6X25        \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "\n",
    "def extract_section_with_layout(pdf_path: str, section_code: str, section_title: str):\n",
    "    \"\"\"\n",
    "    Finds a specified section, locates 'Reqd. QTY', extracts in layout mode,\n",
    "    then parses each part and variant into ref_no, part_no, description, remarks.\n",
    "    Stops collecting once it encounters any line containing 'PART', 'NO', and 'INDEX'.\n",
    "    Returns a DataFrame with columns ref_no, part_no, description, remarks.\n",
    "    \"\"\"\n",
    "    code = section_code.upper()\n",
    "    title = section_title.upper()\n",
    "\n",
    "    next_sec_re     = re.compile(r'^[A-Z]+-\\d+(?:-\\d+)*', re.IGNORECASE)\n",
    "    table_header_re = re.compile(r'\\bReqd\\.?\\s*QTY\\b', re.IGNORECASE)\n",
    "    part_no_re      = re.compile(r'\\b[0-9]{5,}(?:-[A-Z0-9-]+)+\\b')\n",
    "    end_re          = re.compile(r'.*PART\\s*NO\\.?\\s*INDEX.*', re.IGNORECASE)\n",
    "\n",
    "    # Phase 1: locate page range\n",
    "    start_page = header_hit = None\n",
    "    end_page = None\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            for ln in (page.extract_text() or \"\").splitlines():\n",
    "                u = ln.strip().upper()\n",
    "                if start_page is None:\n",
    "                    if ((\"FRAMEGROUP\" in u and u.startswith(code) and title in u)\n",
    "                        or (u.startswith(code) and title in u)):\n",
    "                        start_page = i\n",
    "                        break\n",
    "                elif not header_hit:\n",
    "                    if table_header_re.search(u):\n",
    "                        header_hit = True\n",
    "                else:\n",
    "                    # skip blank lines to avoid u.split()[0] errors\n",
    "                    if not u:\n",
    "                        continue\n",
    "                    first_token = u.split()[0]\n",
    "                    if next_sec_re.match(u) and first_token != code:\n",
    "                        end_page = i\n",
    "                        break\n",
    "            if end_page is not None:\n",
    "                break\n",
    "        if start_page is None or not header_hit:\n",
    "            raise ValueError(f\"Section '{section_code} {section_title}' not found or missing table header.\")\n",
    "        if end_page is None:\n",
    "            end_page = len(pdf.pages)\n",
    "\n",
    "        # Phase 2: collect layout-preserved lines\n",
    "        collected = []\n",
    "        in_table = False\n",
    "        stop_all = False\n",
    "        for pi in range(start_page, end_page):\n",
    "            for ln in (pdf.pages[pi].extract_text(layout=True) or \"\").splitlines():\n",
    "                u = ln.strip().upper()\n",
    "                if end_re.match(u):\n",
    "                    stop_all = True\n",
    "                    break\n",
    "                if not in_table:\n",
    "                    if table_header_re.search(u):\n",
    "                        in_table = True\n",
    "                    continue\n",
    "                # again guard against blank\n",
    "                if not u:\n",
    "                    collected.append(ln)\n",
    "                    continue\n",
    "                first_token = u.split()[0]\n",
    "                if next_sec_re.match(u) and first_token != code:\n",
    "                    break\n",
    "                collected.append(ln)\n",
    "            if stop_all:\n",
    "                break\n",
    "\n",
    "    # Phase 3: group into per-part buffers\n",
    "    records = []\n",
    "    last_ref = \"\"\n",
    "    for ln in collected:\n",
    "        m_pno = part_no_re.search(ln)\n",
    "        if m_pno:\n",
    "            m_ref = re.match(r'^\\s*(?:\\((\\d+)\\)|(\\d+))\\s+', ln)\n",
    "            if m_ref:\n",
    "                last_ref = m_ref.group(1) or m_ref.group(2)\n",
    "            records.append({\n",
    "                \"ref\":      last_ref,\n",
    "                \"part_no\":  m_pno.group(0),\n",
    "                \"buf\":      [ln[m_pno.end():].strip()]\n",
    "            })\n",
    "        else:\n",
    "            if not records:\n",
    "                continue\n",
    "            txt = ln.strip()\n",
    "            if re.fullmatch(r'\\d+', txt) or re.fullmatch(r'\\d{4}\\.\\d{2}\\.\\d{2}', txt):\n",
    "                continue\n",
    "            records[-1][\"buf\"].append(txt)\n",
    "\n",
    "    # Phase 4: parse each buffer directly into column-lists\n",
    "    ref_nos      = []\n",
    "    part_nos     = []\n",
    "    descriptions = []\n",
    "    remarks_list = []\n",
    "\n",
    "    for rec in records:\n",
    "        raw = \" \".join(rec[\"buf\"])\n",
    "        raw = raw.replace('∙','').replace('•','').replace('\\uf020','')\n",
    "        raw = re.sub(r'\\s+', ' ', raw).strip()\n",
    "\n",
    "        idx       = raw.find(\"--------\")\n",
    "        desc_part = raw[:idx].strip() if idx != -1 else raw\n",
    "        cat_part  = raw[idx+8:].strip() if idx != -1 else \"\"\n",
    "        cat_part  = re.sub(r'^[0-9]+\\s*', '', cat_part)\n",
    "        desc_part = re.sub(r'\\s\\d+(?:\\s+\\d+)+.*$', '', desc_part).strip()\n",
    "\n",
    "        # clean up description\n",
    "        desc_part = re.sub(r'\\.{2,}\\s+\\d.*$', '', desc_part).strip()\n",
    "        desc_part = re.sub(r'\\s+GK[A-Za-z0-9]+\\s*$', '', desc_part)\n",
    "        desc_part = re.sub(r'\\s+(?:-+|\\d+)+\\s*$', '', desc_part)\n",
    "        desc      = re.sub(r'\\s+\\d+\\s+\\d{4}\\.\\d{2}\\.\\d{2}.*$', \"\", desc_part).strip()\n",
    "        desc      = re.sub(r'(?:\\s+(?:\\(\\d+\\)|-+|\\d+))+$',     \"\", desc).strip()\n",
    "        desc      = re.sub(r'\\.{2,}$',                         \"\", desc).strip()\n",
    "        desc      = re.sub(r'(?:\\s+[A-Z])+$',                  \"\", desc).strip()\n",
    "        desc      = re.sub(r'\\s+[-\\d ]+$',                     \"\", desc).strip()\n",
    "        desc      = \"\" if not re.search(r'[A-Za-z]', desc) else desc\n",
    "\n",
    "        # clean up catalogue codes → remarks\n",
    "        if cat_part.upper().startswith(\"GK\") and len(cat_part) > 8:\n",
    "            cat_clean = cat_part[8:].split()[0]\n",
    "        else:\n",
    "            m_codes   = re.match(r'[-\\s]*([0-9A-Z,\\s]+)', cat_part)\n",
    "            raw_codes = m_codes.group(1) if m_codes else \"\"\n",
    "            cat_clean = raw_codes.replace(\" \", \"\")\n",
    "            cat_clean = re.sub(r'([A-Z])(?=\\d)', r'\\1,', cat_clean)\n",
    "            cat_clean = re.sub(r'(?<=[0-9A-Z]{2})(?=[A-Z]{2}(?:,|$))', ',', cat_clean)\n",
    "        cat_clean    = re.sub(r'\\d{4}$', '', cat_clean)\n",
    "        tokens       = [t for t in cat_clean.split(',') if t]\n",
    "        if len(tokens) > 1 and re.fullmatch(r'[A-Z]+', tokens[0]):\n",
    "            m = re.match(r'^(\\d+)', tokens[1])\n",
    "            if m:\n",
    "                tokens[0] = m.group(1) + tokens[0]\n",
    "        seen         = set()\n",
    "        final_codes  = [c for c in tokens if c not in seen and not seen.add(c)]\n",
    "        remarks      = \",\".join(final_codes)\n",
    "\n",
    "        # adjust part_no suffix logic\n",
    "        m3 = re.match(r'^(.+?)([A-Z]{3,})$', rec[\"part_no\"])\n",
    "        if m3:\n",
    "            core, suf = m3.group(1), m3.group(2)\n",
    "            part_no    = core + suf[:2]\n",
    "            desc       = f\"{suf[2:]} {desc}\".strip()\n",
    "        else:\n",
    "            part_no = rec[\"part_no\"]\n",
    "\n",
    "        # append to column lists\n",
    "        ref_nos.append(rec[\"ref\"])\n",
    "        part_nos.append(part_no)\n",
    "        descriptions.append(desc)\n",
    "        remarks_list.append(remarks)\n",
    "\n",
    "    # build and return DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'ref_no':      ref_nos,\n",
    "        'part_no':     part_nos,\n",
    "        'description': descriptions,\n",
    "        'remarks':     remarks_list\n",
    "    })\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file = \"CRF1000 A_PC_13MJPG02_(G.H).pdf\"\n",
    "    df = extract_section_with_layout(pdf_file, \"E-5\", \"RIGHT CRANKCASE COVER(CRF1000/CRF1000A)\")\n",
    "    print(df.tail(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b5ae4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 1560 rows to all_sections2.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "\n",
    "def extract_section_with_layout(pdf_path: str, section_code: str, section_title: str):\n",
    "    \"\"\"\n",
    "    Finds a specified section, locates 'Reqd. QTY', extracts in layout mode,\n",
    "    then parses each part and variant into ref_no, part_no, description, remarks.\n",
    "    Stops collecting once it encounters any line containing 'PART', 'NO', and 'INDEX'.\n",
    "    Returns a DataFrame with columns ref_no, part_no, description, remarks.\n",
    "    \"\"\"\n",
    "    code = section_code.upper()\n",
    "    title = section_title.upper()\n",
    "\n",
    "    next_sec_re     = re.compile(r'^[A-Z]+-\\d+(?:-\\d+)*', re.IGNORECASE)\n",
    "    table_header_re = re.compile(r'\\bReqd\\.?\\s*QTY\\b', re.IGNORECASE)\n",
    "    part_no_re      = re.compile(r'\\b[0-9]{5,}(?:-[A-Z0-9-]+)+\\b')\n",
    "    end_re          = re.compile(r'.*PART\\s*NO\\.?\\s*INDEX.*', re.IGNORECASE)\n",
    "\n",
    "    # Phase 1: locate page range\n",
    "    start_page = header_hit = None\n",
    "    end_page = None\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            for ln in (page.extract_text() or \"\").splitlines():\n",
    "                u = ln.strip().upper()\n",
    "                if start_page is None:\n",
    "                    if ((\"FRAMEGROUP\" in u and u.startswith(code) and title in u)\n",
    "                        or (u.startswith(code) and title in u)):\n",
    "                        start_page = i\n",
    "                        break\n",
    "                elif not header_hit:\n",
    "                    if table_header_re.search(u):\n",
    "                        header_hit = True\n",
    "                else:\n",
    "                    # skip blank lines to avoid u.split()[0] errors\n",
    "                    if not u:\n",
    "                        continue\n",
    "                    first_token = u.split()[0]\n",
    "                    if next_sec_re.match(u) and first_token != code:\n",
    "                        end_page = i\n",
    "                        break\n",
    "            if end_page is not None:\n",
    "                break\n",
    "        if start_page is None or not header_hit:\n",
    "            raise ValueError(f\"Section '{section_code} {section_title}' not found or missing table header.\")\n",
    "        if end_page is None:\n",
    "            end_page = len(pdf.pages)\n",
    "\n",
    "        # Phase 2: collect layout-preserved lines\n",
    "        collected = []\n",
    "        in_table = False\n",
    "        stop_all = False\n",
    "        for pi in range(start_page, end_page):\n",
    "            for ln in (pdf.pages[pi].extract_text(layout=True) or \"\").splitlines():\n",
    "                u = ln.strip().upper()\n",
    "                if end_re.match(u):\n",
    "                    stop_all = True\n",
    "                    break\n",
    "                if not in_table:\n",
    "                    if table_header_re.search(u):\n",
    "                        in_table = True\n",
    "                    continue\n",
    "                # again guard against blank\n",
    "                if not u:\n",
    "                    collected.append(ln)\n",
    "                    continue\n",
    "                first_token = u.split()[0]\n",
    "                if next_sec_re.match(u) and first_token != code:\n",
    "                    break\n",
    "                collected.append(ln)\n",
    "            if stop_all:\n",
    "                break\n",
    "\n",
    "    # Phase 3: group into per-part buffers\n",
    "    records = []\n",
    "    last_ref = \"\"\n",
    "    for ln in collected:\n",
    "        m_pno = part_no_re.search(ln)\n",
    "        if m_pno:\n",
    "            m_ref = re.match(r'^\\s*(?:\\((\\d+)\\)|(\\d+))\\s+', ln)\n",
    "            if m_ref:\n",
    "                last_ref = m_ref.group(1) or m_ref.group(2)\n",
    "            records.append({\n",
    "                \"ref\":      last_ref,\n",
    "                \"part_no\":  m_pno.group(0),\n",
    "                \"buf\":      [ln[m_pno.end():].strip()]\n",
    "            })\n",
    "        else:\n",
    "            if not records:\n",
    "                continue\n",
    "            txt = ln.strip()\n",
    "            if re.fullmatch(r'\\d+', txt) or re.fullmatch(r'\\d{4}\\.\\d{2}\\.\\d{2}', txt):\n",
    "                continue\n",
    "            records[-1][\"buf\"].append(txt)\n",
    "\n",
    "    # Phase 4: parse each buffer directly into column-lists\n",
    "    ref_nos      = []\n",
    "    part_nos     = []\n",
    "    descriptions = []\n",
    "    remarks_list = []\n",
    "\n",
    "    for rec in records:\n",
    "        raw = \" \".join(rec[\"buf\"])\n",
    "        raw = raw.replace('∙','').replace('•','').replace('\\uf020','')\n",
    "        raw = re.sub(r'\\s+', ' ', raw).strip()\n",
    "\n",
    "        idx       = raw.find(\"--------\")\n",
    "        desc_part = raw[:idx].strip() if idx != -1 else raw\n",
    "        cat_part  = raw[idx+8:].strip() if idx != -1 else \"\"\n",
    "        cat_part  = re.sub(r'^[0-9]+\\s*', '', cat_part)\n",
    "        # strip quantity columns from description only\n",
    "        desc_part = re.sub(r'\\s\\d+(?:\\s+\\d+)+.*$', '', desc_part).strip()\n",
    "\n",
    "        # clean up description\n",
    "        desc_part = re.sub(r'\\.{2,}\\s+\\d.*$', '', desc_part).strip()\n",
    "        desc_part = re.sub(r'\\s+GK[A-Za-z0-9]+\\s*$', '', desc_part)\n",
    "        desc_part = re.sub(r'\\s+(?:-+|\\d+)+\\s*$', '', desc_part)\n",
    "        desc      = re.sub(r'\\s+\\d+\\s+\\d{4}\\.\\d{2}\\.\\d{2}.*$', \"\", desc_part).strip()\n",
    "        desc      = re.sub(r'(?:\\s+(?:\\(\\d+\\)|-+|\\d+))+$',     \"\", desc).strip()\n",
    "        desc      = re.sub(r'\\.{2,}$',                         \"\", desc).strip()\n",
    "        desc      = re.sub(r'(?:\\s+[A-Z])+$',                  \"\", desc).strip()\n",
    "        desc      = re.sub(r'\\s+[-\\d ]+$',                     \"\", desc).strip()\n",
    "        desc      = \"\" if not re.search(r'[A-Za-z]', desc) else desc\n",
    "\n",
    "        # clean up catalogue codes → remarks\n",
    "        if cat_part.upper().startswith(\"GK\") and len(cat_part) > 8:\n",
    "            cat_clean = cat_part[8:].split()[0]\n",
    "        else:\n",
    "            m_codes   = re.match(r'[-\\s]*([0-9A-Z,\\s]+)', cat_part)\n",
    "            raw_codes = m_codes.group(1) if m_codes else \"\"\n",
    "            cat_clean = raw_codes.replace(\" \", \"\")\n",
    "            cat_clean = re.sub(r'([A-Z])(?=\\d)', r'\\1,', cat_clean)\n",
    "            cat_clean = re.sub(r'(?<=[0-9A-Z]{2})(?=[A-Z]{2}(?:,|$))', ',', cat_clean)\n",
    "        cat_clean    = re.sub(r'\\d{4}$', '', cat_clean)\n",
    "        tokens       = [t for t in cat_clean.split(',') if t]\n",
    "        if len(tokens) > 1 and re.fullmatch(r'[A-Z]+', tokens[0]):\n",
    "            m = re.match(r'^(\\d+)', tokens[1])\n",
    "            if m:\n",
    "                tokens[0] = m.group(1) + tokens[0]\n",
    "        seen         = set()\n",
    "        final_codes  = [c for c in tokens if c not in seen and not seen.add(c)]\n",
    "        remarks      = \",\".join(final_codes)\n",
    "\n",
    "        # adjust part_no suffix logic\n",
    "        m3 = re.match(r'^(.+?)([A-Z]{3,})$', rec[\"part_no\"])\n",
    "        if m3:\n",
    "            core, suf = m3.group(1), m3.group(2)\n",
    "            part_no    = core + suf[:2]\n",
    "            desc       = f\"{suf[2:]} {desc}\".strip()\n",
    "        else:\n",
    "            part_no = rec[\"part_no\"]\n",
    "\n",
    "        ref_nos.append(rec[\"ref\"])\n",
    "        part_nos.append(part_no)\n",
    "        descriptions.append(desc)\n",
    "        remarks_list.append(remarks)\n",
    "\n",
    "    # build and return DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'ref_no':      ref_nos,\n",
    "        'part_no':     part_nos,\n",
    "        'description': descriptions,\n",
    "        'remarks':     remarks_list\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def extract_all_sections_one_pass(pdf_path: str, output_csv: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Opens the PDF once, walks through it page by page, detects sections via next_sec_re,\n",
    "    collects each section’s lines (with the shim‐prefix_re logic you added),\n",
    "    and as soon as any end_re is hit, stops the entire extraction afterwards.\n",
    "    Writes CSV with columns section_no, section_name, ref_no, part_no, description, remarks.\n",
    "    \"\"\"\n",
    "    next_sec_re     = re.compile(r'^[A-Z]+-\\d+(?:-\\d+)*', re.IGNORECASE)\n",
    "    table_header_re = re.compile(r'\\bReqd\\.?\\s*QTY\\b', re.IGNORECASE)\n",
    "    part_no_re      = re.compile(r'\\b[0-9]{5,}(?:-[A-Z0-9-]+)+\\b')\n",
    "    end_re          = re.compile(r'.*PART\\s*NO\\.?\\s*INDEX.*', re.IGNORECASE)\n",
    "\n",
    "    section_nos   = []\n",
    "    section_names = []\n",
    "    ref_nos       = []\n",
    "    part_nos      = []\n",
    "    descriptions  = []\n",
    "    remarks_list  = []\n",
    "\n",
    "    current = None\n",
    "    done    = False\n",
    "\n",
    "    def _flush(cur):\n",
    "        \"\"\"Phase 3+4 verbatim, with your prefix_re shim logic and all the desc/cat fixes.\"\"\"\n",
    "        records = []; last_ref = \"\"\n",
    "        prefix_re = re.compile(r'^\\s*\\(?(\\d+)\\)?\\s+(' + part_no_re.pattern + r')', re.IGNORECASE)\n",
    "\n",
    "        # Phase 3: grouping\n",
    "        for ln in cur['collected']:\n",
    "            # same grouping logic\n",
    "            m0 = prefix_re.match(ln)\n",
    "            if m0:\n",
    "                last_ref, pno = m0.group(1), m0.group(2)\n",
    "                rest = ln[m0.end():].strip()\n",
    "                records.append({'ref': last_ref, 'part_no': pno, 'buf': [rest]})\n",
    "            else:\n",
    "                m_pno = part_no_re.search(ln)\n",
    "                if m_pno:\n",
    "                    pno  = m_pno.group(0)\n",
    "                    rest = ln[m_pno.end():].strip()\n",
    "                    records.append({'ref': last_ref, 'part_no': pno, 'buf': [rest]})\n",
    "                else:\n",
    "                    if not records:\n",
    "                        continue\n",
    "                    txt = ln.strip()\n",
    "                    if re.fullmatch(r'\\d+', txt) or re.fullmatch(r'\\d{4}\\.\\d{2}\\.\\d{2}', txt):\n",
    "                        continue\n",
    "                    records[-1]['buf'].append(txt)\n",
    "\n",
    "        # Phase 4: parsing & cleanup\n",
    "        for rec in records:\n",
    "            raw = \" \".join(rec['buf']).replace('∙','').replace('•','').replace('\\uf020','')\n",
    "            raw = re.sub(r'\\s+', ' ', raw).strip()\n",
    "\n",
    "            idx = raw.find(\"--------\")\n",
    "            desc_part = raw[:idx].strip() if idx != -1 else raw\n",
    "            cat_part  = raw[idx+8:].strip() if idx != -1 else \"\"\n",
    "\n",
    "            # — NEW: strip any stray leading serials from cat_part\n",
    "            cat_part = re.sub(r'^[0-9]+\\s*', '', cat_part)\n",
    "\n",
    "            # — NEW: strip quantity columns from desc_part\n",
    "            desc_part = re.sub(r'\\s\\d+(?:\\s+\\d+)+.*$', '', desc_part).strip()\n",
    "\n",
    "            # description cleanup\n",
    "            desc_part = re.sub(r'\\.{2,}\\s+\\d.*$', '', desc_part).strip()\n",
    "            desc_part = re.sub(r'\\s+GK[A-Za-z0-9]+\\s*$', '', desc_part)\n",
    "            desc_part = re.sub(r'\\s+(?:-+|\\d+)+\\s*$', '', desc_part)\n",
    "            desc = re.sub(r'\\s+\\d+\\s+\\d{4}\\.\\d{2}\\.\\d{2}.*$', \"\", desc_part).strip()\n",
    "            desc = re.sub(r'(?:\\s+(?:\\(\\d+\\)|-+|\\d+))+$', \"\", desc).strip()\n",
    "            desc = re.sub(r'\\.{2,}$', \"\", desc).strip()\n",
    "            desc = re.sub(r'(?:\\s+[A-Z])+$', \"\", desc).strip()\n",
    "            desc = \"\" if not re.search(r'[A-Za-z]', desc) else desc\n",
    "\n",
    "            # remarks cleanup\n",
    "            if cat_part.upper().startswith(\"GK\") and len(cat_part) > 8:\n",
    "                cat_clean = cat_part[8:].split()[0]\n",
    "            else:\n",
    "                m_codes   = re.match(r'[-\\s]*([0-9A-Z,\\s]+)', cat_part)\n",
    "                raw_codes = m_codes.group(1) if m_codes else \"\"\n",
    "                cat_clean = raw_codes.replace(\" \", \"\")\n",
    "                cat_clean = re.sub(r'([A-Z])(?=\\d)', r'\\1,', cat_clean)\n",
    "                cat_clean = re.sub(r'(?<=[0-9A-Z]{2})(?=[A-Z]{2}(?:,|$))', ',', cat_clean)\n",
    "            cat_clean = re.sub(r'\\d{4}$', '', cat_clean)\n",
    "\n",
    "            # — NEW: if first token is pure letters but second starts with a digit, prefix it\n",
    "            tokens = [t for t in cat_clean.split(',') if t]\n",
    "            if len(tokens) > 1 and re.fullmatch(r'[A-Z]+', tokens[0]):\n",
    "                m = re.match(r'^(\\d+)', tokens[1])\n",
    "                if m:\n",
    "                    tokens[0] = m.group(1) + tokens[0]\n",
    "\n",
    "            # dedupe\n",
    "            seen  = set()\n",
    "            codes = [c for c in tokens if c not in seen and not seen.add(c)]\n",
    "            remarks = \",\".join(codes)\n",
    "\n",
    "            # part_no suffix logic\n",
    "            m3 = re.match(r'^(.+?)([A-Z]{3,})$', rec['part_no'])\n",
    "            if m3:\n",
    "                core, suf = m3.group(1), m3.group(2)\n",
    "                pno        = core + suf[:2]\n",
    "                desc       = f\"{suf[2:]} {desc}\".strip()\n",
    "            else:\n",
    "                pno = rec['part_no']\n",
    "\n",
    "            section_nos.append(cur['code'])\n",
    "            section_names.append(cur['title'])\n",
    "            ref_nos.append(rec['ref'])\n",
    "            part_nos.append(pno)\n",
    "            descriptions.append(desc)\n",
    "            remarks_list.append(remarks)\n",
    "\n",
    "    # --- the rest of extract_all_sections_one_pass is unchanged ---\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            plain  = (page.extract_text() or \"\").splitlines()\n",
    "            layout = (page.extract_text(layout=True) or \"\").splitlines()\n",
    "\n",
    "            for ln in plain:\n",
    "                u = ln.strip().upper()\n",
    "                if next_sec_re.match(u):\n",
    "                    if current:\n",
    "                        _flush(current)\n",
    "                    parts = ln.strip().split(None, 1)\n",
    "                    raw_title = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "                    title     = re.sub(r'\\b[A-Z]+GROUP\\b\\s*', '', raw_title, re.IGNORECASE)\n",
    "                    current = {\n",
    "                        'code':       parts[0].upper(),\n",
    "                        'title':      title,\n",
    "                        'header_hit': False,\n",
    "                        'collected':  []\n",
    "                    }\n",
    "\n",
    "            if current:\n",
    "                for ln in layout:\n",
    "                    u = ln.strip().upper()\n",
    "                    if end_re.match(u):\n",
    "                        _flush(current)\n",
    "                        done = True\n",
    "                        current = None\n",
    "                        break\n",
    "                    if not current['header_hit']:\n",
    "                        if table_header_re.search(u):\n",
    "                            current['header_hit'] = True\n",
    "                        continue\n",
    "                    first_token = u.split()[0] if u else \"\"\n",
    "                    if next_sec_re.match(u) and first_token != current['code']:\n",
    "                        _flush(current)\n",
    "                        current = None\n",
    "                        break\n",
    "                    collected = current['collected']\n",
    "                    collected.append(ln)\n",
    "\n",
    "    if current and not done:\n",
    "        _flush(current)\n",
    "\n",
    "    final_df = pd.DataFrame({\n",
    "        'section_no':   section_nos,\n",
    "        'section_name': section_names,\n",
    "        'ref_no':       ref_nos,\n",
    "        'part_no':      part_nos,\n",
    "        'description':  descriptions,\n",
    "        'remarks':      remarks_list\n",
    "    })\n",
    "    final_df.to_csv(output_csv, index=False)\n",
    "    return final_df\n",
    "\n",
    "\n",
    "pdf_file = \"NC750XAP_13MKWM02_PC_2022_2023.pdf\"\n",
    "df = extract_all_sections_one_pass(pdf_file, \"all_sections.csv\")\n",
    "print(f\"Written {len(df)} rows to all_sections2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca03950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
